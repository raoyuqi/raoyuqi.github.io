{"meta":{"title":"奇遇的博客","subtitle":"","description":"","author":"John Doe","url":"https://raoyuqi.github.io","root":"/"},"pages":[{"title":"文章分类","date":"2023-07-19T12:40:46.000Z","updated":"2023-07-19T13:37:47.381Z","comments":true,"path":"categories/index.html","permalink":"https://raoyuqi.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Mesh合并","slug":"unity/性能优化/Mesh合并","date":"2023-09-23T03:40:42.000Z","updated":"2023-09-24T07:05:33.847Z","comments":false,"path":"2023/09/23/unity/性能优化/Mesh合并/","link":"","permalink":"https://raoyuqi.github.io/2023/09/23/unity/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/Mesh%E5%90%88%E5%B9%B6/","excerpt":"","text":"1. 前言要在屏幕上绘制游戏对象，引擎必须向图形 API（例如 OpenGL 或 Direct3D）发出绘制调用。绘制调用通常为资源密集型操作，图形 API 为每次绘制调用执行大量工作，从而导致 CPU 端的性能开销。此开销的主要原因是绘制调用之间的状态变化（例如切换到不同材质），而这种情况会导致图形驱动程序中执行资源密集型验证和转换步骤。 Unity可以通过以下方法进行优化： 动态批处理：对于足够小的网格，此方法会在 CPU 上转换网格的顶点，将许多相似顶点组合在一起，并一次性绘制它们。 静态批处理：将静态（不移动）游戏对象组合成大网格，并以较快的速度渲染它们。 但是，也有一些缺点；静态批处理会导致内存和存储开销，动态批处理会产生一些 CPU 开销。 除此之外还可以利用Unity提供的 Mesh.CombineMeshes API在运行是合并网格，最近在优化具有换装需求的项目时正好使用到。 2. 实现2.1 流程前提：使用相同材质 收集需要合并的Texture 收集需要合并的UV信息 合并根节点下的Mesh、Texture、UV 2.2 收集需要合并Texture每个部位用到的Texture不同，因此先合并贴图： 12345678910111213141516171819202122232425/// &lt;summary&gt;/// 收集组件的贴图/// &lt;/summary&gt;/// &lt;param name=&quot;model&quot;&gt;模型根节点&lt;/param&gt; public List&lt;Texture2D&gt; CollectCombineTextures(GameObject model)&#123; // 模型中所有的SkinnedMeshRenderer var skinnedMeshRenderers = model.GetComponentsInChildren&lt;SkinnedMeshRenderer&gt;(); // 需要合并的贴图 var textureList = new List&lt;Texture2D&gt;(); // 遍历SkinnedMeshRenderer for (int i = 0; i &lt; skinnedMeshRenderers.Length; i++) &#123; var skinMeshRenderer = skinnedMeshRenderers[i]; var mat = skinMeshRenderer.sharedMaterial; if (mat == null) continue; // var texture2d = mat.GetTexture(&quot;_BaseMap&quot;) as Texture2D; var texture2d = mat.mainTexture as Texture2D; textureList.Add(texture2d); return textureList; &#125;&#125; 2.3 收集UV数据在本次实践中，shader用到了uv2，因此需要一起合并，类似可以拓展到uv3，uv4… 123456789101112131415161718public List&lt;Vector2[]&gt; CollectCombineUVList(GameObject model, List&lt;Vector2[]&gt; uv1List, ref int uv1Count, List&lt;Vector2[]&gt; uv2List, ref int uv2Count)&#123; // 模型中所有的SkinnedMeshRenderer var skinnedMeshRenderers = model.GetComponentsInChildren&lt;SkinnedMeshRenderer&gt;(); // 遍历SkinnedMeshRenderer for (int i = 0; i &lt; skinnedMeshRenderers.Length; i++) &#123; var skinMeshRenderer = skinnedMeshRenderers[i]; // 存储mesh的uv uv1List.Add(skinMeshRenderer.sharedMesh.uv); uv1Count += skinMeshRenderer.sharedMesh.uv.Length; uv2List.Add(skinMeshRenderer.sharedMesh.uv); uv2Count += skinMeshRenderer.sharedMesh.uv.Length; &#125;&#125; 2.4 合并完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122private void SkinnedMeshCombine(GameObject model)&#123; // 模型中所有的SkinnedMeshRenderer var skinnedMeshRenderers = model.GetComponentsInChildren&lt;SkinnedMeshRenderer&gt;(); var combineList = new List&lt;CombineInstance&gt;(); // 骨骼数据 var bones = new List&lt;Transform&gt;(); // uv var uvCount = 0; var uvList = new List&lt;Vector2[]&gt;(); // uv2的起始位置 var uv2StartIndex = 0; // 需要合并的贴图 var textureList = new List&lt;Texture2D&gt;(); Material material = null; // 骨骼 var allBones = model.GetComponentsInChildren&lt;Transform&gt;(); var ok = false; // 遍历SkinnedMeshRenderer for (int i = 0; i &lt; skinnedMeshRenderers.Length; i++) &#123; var skinMeshRenderer = skinnedMeshRenderers[i]; if (material == null) &#123; //返回分配给渲染器的第一个材质 material = skinMeshRenderer.sharedMaterial; &#125; // 需要合并的网格 var combine = new CombineInstance(); combine.mesh = skinMeshRenderer.sharedMesh; combine.transform = skinMeshRenderer.transform.localToWorldMatrix; combineList.Add(combine); // 贴图 var texture2d = mat.mainTexture as Texture2D; textureList.Add(texture2d); // 收集需要合并的骨骼信息 for(int j = 0; j &lt; skinMeshRenderer.bones.Length; j++) &#123; for(int k = 0; k &lt; allBones.Length; k++) &#123; if(smr.bones[j].name == allBones[k].name) &#123; bones.Add(allBones[k]); break; &#125; &#125; &#125; // 存储mesh的uv uvList.Add(skinMeshRenderer.sharedMesh.uv); uvCount += skinMeshRenderer.sharedMesh.uv.Length; if (skinMeshRenderer.name == &quot;&quot;) &#123; // 针对某个mesh使用了uv2 ok = true; uv2List.Add(render.sharedMesh.uv2); uv2Count += render.sharedMesh.uv2.Length; &#125; if (!ok) uv2StartIndex = uvCount; // 销毁子物体 Object.Destroy(skinMeshRenderer.gameObject); &#125; // 开始合并，创建一个新的节点 var combineObj = new GameObject(&quot;Combine&quot;); combineObj.transform.parent = model.transform; // 贴图合并 var skinnedMeshAtlas = new Texture2D(1024, 1024); var packingResults = skinnedMeshAtlas.PackTextures(textureList.ToArray(), 0); // 设置uv var atlasUVs = new Vector2[uvCount]; // 大Mesh的UV列表 var counter = 0; for (int index = 0; index &lt; uvList.Count; ++index) &#123; foreach (Vector2 uv in uvList[index]) &#123; atlasUVs[counter].x = Mathf.Lerp(packingResults[index].xMin, packingResults[index].xMax, uv.x); atlasUVs[counter].y = Mathf.Lerp(packingResults[index].yMin, packingResults[index].yMax, uv.y); counter++; &#125; &#125; // uv2采样 var meshAtlas2 = new Texture2D(512, 512); var packingResults2 = meshAtlas2.PackTextures(new Texture2D[] &#123; numberData.m_NumTexture &#125;, 0); var atlasUV2s = new Vector2[uvCount]; // 大Mesh的UV2列表 counter = uv2StartIndex; for (int index = 0; index &lt; uv2List.Count; ++index) &#123; foreach (Vector2 uv in uv2List[index]) &#123; atlasUV2s[counter].x = Mathf.Lerp(packingResults2[index].xMin, packingResults2[index].xMax, uv.x); atlasUV2s[counter].y = Mathf.Lerp(packingResults2[index].yMin, packingResults2[index].yMax, uv.y); counter++; &#125; &#125; var smr = combineObj.AddComponent&lt;SkinnedMeshRenderer&gt;(); smr.sharedMesh = new Mesh(); smr.sharedMesh.CombineMeshes(combineList.ToArray(), true, false); smr.sharedMesh.uv = atlasUVs; smr.sharedMesh.uv2 = atlasUV2s; smr.material = material; smr.material.mainTexture = skinnedMeshAtlas; smr.bones = bones.ToArray(); // smr.rootBone = transform;&#125; 原本模型下有多个SkinnedMeshRenderer，合并后只有一个了（旧的都被删除），虽然占用的内存变多了，但是原本渲染一个模型需要渲染头、四肢、身体、鞋子，和额外的装备，每部分都是不同的mesh，这样至少需要4个Draw Call（没有额外装备的情况），合并mesh和texture后，只需要一个Draw Call便可完整绘制，内存的付出是值得的。 2.5 另一种合并Texture的方式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051Texture2D Combine(Texture2D tex1, Texture2D tex2)&#123; int length = tex1.width * 2; var blcokBytes = 0; // 和不同的压缩算法相关 byte[] data = null; switch (tex1.format) &#123; case TextureFormat.DXT1: case TextureFormat.ETC_RGB4: case TextureFormat.ETC2_RGB: blcokBytes = 8; data = new byte[length / 2 * length / 2]; break; case TextureFormat.DXT5: case TextureFormat.ETC2_RGBA8: case TextureFormat.ASTC_4x4: blcokBytes = 16; data = new byte[length * length / 2]; break; default: UnityEngine.Debug.Log(&quot;Not supported.&quot;); return null; &#125; //填充第一张图到左边 CombineBlocks(tex1.GetRawTextureData(), data, 0, 0, tex1.width, 4, blcokBytes, length); //填充第二张图到右边 CombineBlocks(tex2.GetRawTextureData(), data, tex1.width, 0, tex2.width, 4, blcokBytes, length); // 合并后的宽高要与两张图合并的尺寸一致 // 这里简单把两张512 x 512的图合成一张大的1024 x 512 var combinedTex = new Texture2D(length, length / 2, tex1.format, false); combinedTex.LoadRawTextureData(data); combinedTex.Apply(false, true); return combinedTex;&#125;void CombineBlocks(byte[] src, byte[] dst, int dstx, int dsty, int width, int block, int bytes, int length)&#123; var dstbx = dstx / block; var dstby = dsty / block; for (int i = 0; i &lt; width / block; i++) &#123; int dstindex = (dstbx + (dstby + i) * (length / block)) * bytes; int srcindex = i * (width / block) * bytes; System.Buffer.BlockCopy(src, srcindex, dst, dstindex, width / block * bytes); &#125;&#125; 合并Texture应遵循： Texture压缩格式一致 Texture为正方形且分辨率一致 申请合并后的Texture数组应和两张图合并的byte数一致，取决于不同压缩算法 常见错误： 合并Texture时，新创建的数据集大于合并的数据集，报错:","categories":[{"name":"Uniy","slug":"Uniy","permalink":"https://raoyuqi.github.io/categories/Uniy/"},{"name":"性能优化","slug":"Uniy/性能优化","permalink":"https://raoyuqi.github.io/categories/Uniy/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"}],"tags":[{"name":"Uniy","slug":"Uniy","permalink":"https://raoyuqi.github.io/tags/Uniy/"},{"name":"性能优化","slug":"性能优化","permalink":"https://raoyuqi.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"name":"合并Mesh","slug":"合并Mesh","permalink":"https://raoyuqi.github.io/tags/%E5%90%88%E5%B9%B6Mesh/"}]},{"title":"2D游戏相机跟随","slug":"unity/mix/2D游戏相机跟随","date":"2023-09-13T14:01:20.000Z","updated":"2023-09-13T14:03:04.953Z","comments":false,"path":"2023/09/13/unity/mix/2D游戏相机跟随/","link":"","permalink":"https://raoyuqi.github.io/2023/09/13/unity/mix/2D%E6%B8%B8%E6%88%8F%E7%9B%B8%E6%9C%BA%E8%B7%9F%E9%9A%8F/","excerpt":"","text":"1. 矩形地图1.1 思路 初始化相机视野边界 相机跟随移动时，将相机视野限制在视野边界内 1.2 实现 初始化地图边界 123456789101112131415161718192021222324// 地图public SpriteRenderer m_Map;// 用BoxCollider2D设置相机视野public BoxCollider2D m_BoxCollider2D;private float m_MinMapEdgeX = 0; // left edge of map in xprivate float m_MaxMapEdgeX = 0; // right edge of map in xprivate float m_MinMapEdgeY = 0; // bottom edge of map in yprivate float m_MaxMapEdgeY = 0; // top edge of map in yprivate void InitMapBorder()&#123; if (this.m_BoxCollider2D == null || this.m_Map == null) return; // 将实际边界减去相机size的宽高，计算出相机中心坐标的移动范围 var mapExtents = this.m_Map.bounds.extents; var cameraExtents = this.m_BoxCollider2D.bounds.extents; this.m_MaxMapEdgeX = mapExtents.x - cameraExtents.x; this.m_MinMapEdgeX = -this.m_MaxMapEdgeX; this.m_MaxMapEdgeY = mapExtents.y - cameraExtents.y; this.m_MinMapEdgeY = -this.m_MaxMapEdgeY;&#125; 相机跟随 123456789101112131415161718192021222324252627282930public Transform m_FollowTarget;private void FixedUpdate()&#123; if (this.m_FollowTarget != null) &#123; var targetPosition = this.m_FollowTarget.position + this.m_Offset; targetPosition = this.GetLimitPosition(targetPosition); this.transform.position = targetPosition; &#125;&#125;// 坐标限制private Vector3 GetLimitPosition(Vector3 pos)&#123; if (pos.x &gt; this.m_MaxMapEdgeX) pos.x = this.m_MaxMapEdgeX; if (pos.x &lt; this.m_MinMapEdgeX) pos.x = this.m_MinMapEdgeX; if (pos.y &gt; this.m_MaxMapEdgeY) pos.y = this.m_MaxMapEdgeY; if (pos.y &lt; this.m_MinMapEdgeY) pos.y = this.m_MinMapEdgeY; return pos;&#125; &lt;/br&gt; 2. 多边形地图2.1 思路 移动实时计算相机的视野边界坐标 判断视野的上下左右边界是否在多边形内 2.2 实现 计算相机视野边界 123456public Camera m_Camera;Vector2 minCameraEdgeX = this.m_Camera.ViewportToWorldPoint(new Vector3(0, 0.5f, this.m_Camera.nearClipPlane)); // left edge of camera in xVector2 maxCameraEdgeX = this.m_Camera.ViewportToWorldPoint(new Vector3(1, 0.5f, this.m_Camera.nearClipPlane)); // right edge of camera in xVector2 minCameraEdgeY = this.m_Camera.ViewportToWorldPoint(new Vector3(0.5f, 0, this.m_Camera.nearClipPlane)); // bottom edge of camera in yVector2 maxCameraEdgeY = this.m_Camera.ViewportToWorldPoint(new Vector3(0.5f, 1, this.m_Camera.nearClipPlane)); // top edge of camera in y 判断点是否在多边形内算法 1234567891011121314151617181920212223242526272829303132/// ray-crossing算法，两点式方程公式：(y-y1)/(y2-y1)=(x-x1)/(x2-x1) 求位于直线上的点(x, y)/// 判断点是否在多边形内./// 注意到如果从P作水平向右的射线的话，如果P在多边形内部，那么这条射线与多边形的交点必为奇数，/// 如果P在多边形外部，则交点个数必为偶数(0也在内)。public static bool PointIsInPolygon(this Vector2 point, Vector2[] polygon)&#123; var count = 0; var len = polygon.Length; var point1 = Vector2.zero; var point2 = Vector2.zero; for (int i = 0; i &lt; len; i++) &#123; point1 = polygon[i]; point2 = polygon[(i + 1) % len]; // 水平边，跳过 if (point1.y == point2.y) continue; // 点不在线段两端点范围内 if (point.y &lt; Mathf.Min(point1.y, point2.y) | point.y &gt; Mathf.Max(point1.y, point2.y)) continue; // 经过点point，往右画一条直线，统计交点count次数 var x = (point.y - point1.y) * (double)(point2.x - point1.x) / (double)(point2.y - point1.y) + point1.x; if (x &gt; point.x) count++; &#125; // 相交奇数次说明在多边形内 return count % 2 == 1;&#125; 完整代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677using UnityEngine;// 位标志public enum OutBoundType&#123; None = 0, Left = 0x0001, Right = 0x0002, Up = 0x0004, Bottom = 0x0008&#125;public class CameraFollowForPolygonMap : MonoBehaviour&#123; public Transform m_FollowTarget; // 地图形状 public Collider2D m_BoudingShape2D; public Camera m_Camera; private Vector3 m_Offset; private Bounds m_Bounds; private void Start() &#123; this.m_Offset = this.transform.position - this.m_FollowTarget.position; this.m_Bounds = this.m_BoudingShape2D.composite.bounds.size == Vector3.zero ? this.m_BoudingShape2D.bounds : this.m_BoudingShape2D.composite.bounds; &#125; private void FixedUpdate() &#123; if (this.m_FollowTarget == null) return; var targetPosition = this.m_FollowTarget.position + this.m_Offset; var lastPosition = this.transform.position; var offset = targetPosition - lastPosition; var boundType = GetCameraOutBoundTypeAfterMoving(offset); if (boundType.HasFlag(OutBoundType.Left) || boundType.HasFlag(OutBoundType.Right)) targetPosition.x = lastPosition.x; if (boundType.HasFlag(OutBoundType.Bottom) || boundType.HasFlag(OutBoundType.Up)) targetPosition.y = lastPosition.y; this.transform.position = targetPosition; &#125; /// 获取相机移动后的越界类型, None: 未出界 private OutBoundType GetCameraOutBoundTypeAfterMoving(Vector2 offset) &#123; Vector2 minCameraEdgeX = this.m_Camera.ViewportToWorldPoint(new Vector3(0, 0.5f, this.m_Camera.nearClipPlane)); // left edge of camera in x Vector2 maxCameraEdgeX = this.m_Camera.ViewportToWorldPoint(new Vector3(1, 0.5f, this.m_Camera.nearClipPlane)); // right edge of camera in x Vector2 minCameraEdgeY = this.m_Camera.ViewportToWorldPoint(new Vector3(0.5f, 0, this.m_Camera.nearClipPlane)); // bottom edge of camera in y Vector2 maxCameraEdgeY = this.m_Camera.ViewportToWorldPoint(new Vector3(0.5f, 1, this.m_Camera.nearClipPlane)); // top edge of camera in y // 这里用的是Unity自带接口判断 var ret = OutBoundType.None; // 左边越界 if (!this.m_Bounds.Contains(minCameraEdgeX + offset)) ret = ret | OutBoundType.Left; // 右边出界 if (!this.m_Bounds.Contains(maxCameraEdgeX + offset)) ret = ret | OutBoundType.Right; // 上边出界 if (!this.m_Bounds.Contains(maxCameraEdgeY + offset)) ret = ret | OutBoundType.Up; // 下边出界 if (!this.m_Bounds.Contains(minCameraEdgeY + offset)) ret = ret | OutBoundType.Bottom; return ret; &#125;&#125;","categories":[{"name":"Uniy","slug":"Uniy","permalink":"https://raoyuqi.github.io/categories/Uniy/"}],"tags":[{"name":"Uniy","slug":"Uniy","permalink":"https://raoyuqi.github.io/tags/Uniy/"},{"name":"Dots","slug":"Dots","permalink":"https://raoyuqi.github.io/tags/Dots/"}]},{"title":"JobSystem","slug":"unity/JobSystem","date":"2023-08-10T13:26:46.000Z","updated":"2023-08-10T13:42:23.482Z","comments":false,"path":"2023/08/10/unity/JobSystem/","link":"","permalink":"https://raoyuqi.github.io/2023/08/10/unity/JobSystem/","excerpt":"","text":"1. 概述Unity的Job System可以很方便的编写多线程代码，多线程可以充分发挥多核的优势。可以单独使用，但为了提高性能，通常结合Burst编译器一起使用，这是专门为Unity的Job System编译作业而设计的。Burst编译器改进了代码生成，从而提高了性能并减少了移动设备上的电池消耗。也可以用在ECS上，实现高性能的面向数据代码。 Job System的调度策略使用了工作窃取策略，以均匀分配跨工作线程共享的任务数量。思想是：成了所有任务的工作线程会查看其它工作线程的任务队列，然后将任务分配给另一个工作线程。 2. Job Types IJob：在job thread运行的单个任务 IJobFor：与IJobParallelFor相同，但允许调度Job，使其不会并行运行 IJobParallelFor：并行运行任务。每个并行运行的工作线程都有一个独占索引，以便安全地访问工作线程之间的共享数据 2.1 IJob定义一个Job： 1234567891011public struct AddJob : IJob&#123; public float a; public float b; public NativeArray&lt;float&gt; result; public void Execute() &#123; result[0] = a + b; &#125;&#125; Job中的变量仅可以使用blittable types或者Unity提供的NativeContainer容器，比如引擎内置的NativeArray或者com.unity.collections package中提供的容器类。 为什么只能使用blittable types？ 为了资源竞争问题，Job System向每个任务发送它需要操作的数据的副本，而不是主线程中对数据的引用。该副本隔离了数据，从而消除了竞争条件。blittable types在这个拷贝过程中不需要做数据转换，因此blittable types在这里是必须的。 Job调度： 1234567891011121314void Start()&#123; var job = new AddJob() &#123; a = 1, b = 2, result = this._result &#125;; // 调度 this._handler = job.Schedule(); // 调用Complete获取结果 this._handler.Complete(); Debug.Log($&quot;Start _result = &#123;this._result[0]&#125;&quot;);&#125; 完整代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152using Unity.Collections;using Unity.Jobs;using UnityEngine;public struct AddJob : IJob&#123; public float a; public float b; public NativeArray&lt;float&gt; result; public void Execute() &#123; result[0] = a + b; &#125;&#125;public class AddJob : MonoBehaviour&#123; private NativeArray&lt;float&gt; _result; private JobHandle _handler; void Start() &#123; this._result = new NativeArray&lt;float&gt;(1, Allocator.Persistent); var job = new AddJob() &#123; a = 1, b = 2, result = this._result &#125;; this._handler = job.Schedule(); this._handler.Complete(); Debug.Log($&quot;Start _result = &#123;this._result[0]&#125;&quot;); &#125; // void Update() // &#123; // if (this._handler.IsCompleted) // &#123; // this._handler.Complete(); // Debug.Log($&quot;Update _result = &#123;this._result[0]&#125;&quot;); // &#125; // &#125; void OnDestroy() &#123; // 释放非托管资源 if (this._result.IsCreated) this._result.Dispose(); &#125;&#125; 2.2 IJobFor与对比IJobFor： 123456789public interface IJobFor&#123; void Execute(int index);&#125;public interface IJob&#123; void Execute();&#125; IJobFor接口的Execute方法多了一个index参数，通过这个参数可以访问Job中的NativeContainer容器，对容器中的元素进行相对独立的操作。除此之外，IJobFor还在任务的调度上提供了更大的灵活性。可以用下面三种方式调度Job： 1234567891011121314public void Update()&#123; ... var position = new NativeArray&lt;Vector3&gt;(500, Allocator.Persistent); var job = new VelocityJob(); // run on main thread job.Run(position.Length); // run on a single worker thread job.Schedule(position.Length, dependency); // run on parallel worker threads job.ScheduleParallel(position.Length, 64, dependency); ...&#125; 以上三种方式都需要传入一个arrayLength参数，这个参数可以控制Execute方法执行的次数。 实际上传入的arrayLength不一定就是数组的长度，它可以是小于数组长度的任意数值。Unity官方例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354using Unity.Collections;using Unity.Jobs;using UnityEngine;public class ApplyVelocityParallelForSample : MonoBehaviour&#123; struct VelocityJob : IJobFor &#123; // By declaring it as read only, multiple jobs are allowed to access the data in parallel [ReadOnly] public NativeArray&lt;Vector3&gt; velocity; // By default containers are assumed to be read &amp; write public NativeArray&lt;Vector3&gt; position; public float deltaTime; public void Execute(int i) &#123; position[i] = position[i] + velocity[i] * deltaTime; &#125; &#125; void Update() &#123; var position = new NativeArray&lt;Vector3&gt;(500, Allocator.Persistent); var velocity = new NativeArray&lt;Vector3&gt;(500, Allocator.Persistent); for (var i = 0; i &lt; velocity.Length; i++) velocity[i] = new Vector3(0, 10, 0); var job = new VelocityJob() &#123; deltaTime = Time.deltaTime, position = position, velocity = velocity &#125;; // run on main thread job.Run(position.Length); //run on a single worker thread var sheduleJobDependency = new JobHandle(); var sheduleJobHandle = job.Schedule(position.Length, sheduleJobDependency); //run on parallel worker threads var sheduleParralelJobHandle = job.ScheduleParallel(position.Length, 64, sheduleJobHandle); sheduleParralelJobHandle.Complete(); Debug.Log(job.position[0]); position.Dispose(); velocity.Dispose(); &#125;&#125; 把velocity标记为ReadOnly时，可以在多个并行的Job中读取velocity数组的内容而不触发safety system。因此应该尽量将Job中只读的数据标记成ReadOnly来最大化性能。 IJobFor的三种不同用法在性能上的表现截图： Job.Run：行在主线程的 Job.Schedule：由于任务窃取的调度策略Job.Schedule也在主线程，当主线程在等待工作（worker）线程执行的过程中也会从任务池中获取任务来执行，从而加快所有任务的完成进度 Job.ScheduleParallel：时间明显要短于前两个，通过ScheduleParallel把任务分发到各个工作线程，让每个线程负责一部分工作 应该尽量使用IJobFor.ScheduleParallel来把任务拆分到多个核心去做并行计算，才能最大化程序的执行效率。 3. 线程本地资源应用场景：每次随机一个方向进行移动： 12345678910111213141516171819202122232425struct RandomVelocityJob : IJobFor&#123; [ReadOnly] public NativeArray&lt;float&gt; speeds; [ReadOnly] public Random random; public float deltaTime; // output public NativeArray&lt;float3&gt; positions; public void Execute(int i) &#123; positions[i] += random.NextFloat3Direction() * speeds[i] * deltaTime; &#125;&#125;var random = new Random(1234);var randomVelocityJob = new RandomVelocityJob&#123; speeds = m_Speeds, random = random, positions = m_Positions, deltaTime = Time.deltaTime,&#125;; NextFloat3Direction方法会改变random的内部状态，由于所有的worker线程会共享并改变random的状态，使random处在竞争条件的状态。加锁是效率比较低的方法，另外一种比较经典的做法是使用线程本地存储（TLS），让每个线程拥有一份自己独有的资源，避免了竞争条件的问题。 使用JobsUtility.MaxJobThreadCount来获取worker的最大数量，为每一个worker线程初始化一个random变量： 1234567private NativeArray&lt;Random&gt; _randoms;this._randoms = new NativeArray&lt;Random&gt;(JobsUtility.MaxJobThreadCount, Allocator.Persistent);for (int i = 0; i &lt; m_Randoms.Length; i++)&#123; _randoms[i] = Random.CreateFromIndex((uint)i);&#125; 在Job中需要知道当前执行的线程ID，可以在Job中声明一个int类型的变量并添加[NativeSetThreadIndex]属性，在job执行的过程中Unity会自动注入Job ID。 这样就可以在Execute方法中利用线程ID获取线程独有的资源了： 123456789101112131415161718192021struct RandomVelocityJob : IJobFor&#123; // input [ReadOnly] public NativeArray&lt;float&gt; speeds; [ReadOnly] public NativeArray&lt;Random&gt; randoms; public float deltaTime; // 自动注入线程Id [NativeSetThreadIndex] private int threadIdx; // output public NativeArray&lt;float3&gt; positions; public void Execute(int i) &#123; positions[i] += randoms[threadIdx].NextFloat3Direction() * speeds[i] * deltaTime; &#125;&#125; 4. Pointers &amp; InterLocked利用IJobFor接口开实现并行求和： 12345678910public struct NaiveParallelCounterJob : IJobFor&#123; [ReadOnly] public NativeArray&lt;int&gt; data; public int sum; public void Execute(int index) &#123; sum += data[index]; &#125;&#125; 这断代码会导致任务完成之后无法获取正确的sum值，因为sum不是以引用的形式传进来的而是直接以值传递的形式进行了赋值，修改： 1234567891011public struct NaiveParallelCounterJob : IJobFor&#123; [ReadOnly] public NativeArray&lt;int&gt; data; // 允许以引用的方式来传递单个值 public NativeReference&lt;int&gt; naiveSum; public void Execute(int index) &#123; naiveSum.Value += data[index]; &#125;&#125; Job在多线程中运行时，对naiveSum变量的访问可能会存在竞争条件，使用TLS解决： 123456789101112131415161718192021222324252627282930313233343536public struct ThreadLocalParallelCounterJob : IJobFor&#123; //input [NativeDisableParallelForRestriction] public NativeArray&lt;int&gt; data; //output [NativeDisableParallelForRestriction] public NativeArray&lt;int&gt; sums; [NativeSetThreadIndex] private int _threadIndex; public void Execute(int index) &#123; sums[_threadIndex] += data[index]; &#125;&#125;public struct TotalSumJob : IJob&#123; [ReadOnly] public NativeArray&lt;int&gt; sums; public NativeReference&lt;int&gt; totalSum; public void Execute() &#123; for (int i = 0; i &lt; sums.Length; i++) &#123; totalSum.Value += sums[i]; &#125; &#125;&#125;// Job依赖var threadLocalCounterJobHandle = threadLocalCounterJob.ScheduleParallel(m_Data.Length, 64, new JobHandle());var totalSumJobHandle = totalSumJob.Schedule(threadLocalCounterJobHandle);totalSumJobHandle.Complete(); 使用Interlocked实现： 12345678910111213public unsafe struct InterlockedParallelCounterJob : IJobFor&#123; //input public NativeArray&lt;int&gt; data; //output [NativeDisableUnsafePtrRestriction] public int* sum; public void Execute(int index) &#123; Interlocked.Add(ref UnsafeUtility.AsRef&lt;int&gt;(sum), data[index]); &#125;&#125; Interlocked可以在不同线程之间以原子操作的方式来修改变量，这样就不用担心竞争条件的问题了。为了在Job中使用指针，需要引入一个新的属性——[NativeDisableUnsafePtrRestriction]。 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125using System.Threading;using Unity.Collections;using Unity.Collections.LowLevel.Unsafe;using Unity.Jobs;using Unity.Jobs.LowLevel.Unsafe;using UnityEngine;public unsafe class ParallelCounter : MonoBehaviour&#123; public struct ThreadLocalParallelCounterJob : IJobFor &#123; //input [NativeDisableParallelForRestriction] public NativeArray&lt;int&gt; data; //output [NativeDisableParallelForRestriction] public NativeArray&lt;int&gt; sums; [NativeSetThreadIndex] private int m_ThreadIndex; public void Execute(int index) &#123; sums[m_ThreadIndex] += data[index]; &#125; &#125; public struct TotalSumJob : IJob &#123; [ReadOnly] public NativeArray&lt;int&gt; sums; public NativeArray&lt;int&gt; totalSum; public void Execute() &#123; for (int i = 0; i &lt; sums.Length; i++) &#123; totalSum[0] += sums[i]; &#125; &#125; &#125; public unsafe struct InterlockedParallelCounterJob : IJobFor &#123; //input public NativeArray&lt;int&gt; data; //output [NativeDisableUnsafePtrRestriction] public int* sum; public void Execute(int index) &#123; Interlocked.Add(ref UnsafeUtility.AsRef&lt;int&gt;(sum), data[index]); &#125; &#125; private static readonly int DATA_COUNT = 100000; private NativeArray&lt;int&gt; _data; private NativeArray&lt;int&gt; _threadLocalSums; void Start() &#123; this._data = new NativeArray&lt;int&gt;(DATA_COUNT, Allocator.Persistent); for (int i = 0; i &lt; DATA_COUNT; i++) this._data[i] = i; this._threadLocalSums = new NativeArray&lt;int&gt;(JobsUtility.MaxJobThreadCount, Allocator.Persistent); ResetThreadLocalSums(); &#125; private void ResetThreadLocalSums() &#123; for (int i = 0; i &lt; this._threadLocalSums.Length; i++) &#123; this._threadLocalSums[i] = 0; &#125; &#125; private void OnDestroy() &#123; this._data.Dispose(); this._threadLocalSums.Dispose(); &#125; void Update() &#123; var threadLocalCounterJob = new ThreadLocalParallelCounterJob &#123; data = this._data, sums = this._threadLocalSums &#125;; var totalSum = new NativeArray&lt;int&gt;(1, Allocator.TempJob); var totalSumJob = new TotalSumJob &#123; sums = this._threadLocalSums, totalSum = totalSum &#125;; var threadLocalCounterJobHandle = threadLocalCounterJob.ScheduleParallel(this._data.Length, 64, new JobHandle()); var totalSumJobHandle = totalSumJob.Schedule(threadLocalCounterJobHandle); totalSumJobHandle.Complete(); ResetThreadLocalSums(); Debug.Log($&quot;[ThreadLocalParallelCounter] Sum = &#123;totalSum[0]&#125;&quot;); totalSum.Dispose(); var sum = (int*)UnsafeUtility.Malloc(UnsafeUtility.SizeOf&lt;int&gt;(), UnsafeUtility.AlignOf&lt;int&gt;(), Allocator.TempJob); *sum = 0; var interlockedParallelCounterJob = new InterlockedParallelCounterJob &#123; data = this._data, sum = sum &#125;; var interlockedCounterJobHandle = interlockedParallelCounterJob.ScheduleParallel(this._data.Length, 64, new JobHandle()); interlockedCounterJobHandle.Complete(); Debug.Log($&quot;[InterlockedParallelCounterJob] Sum = &#123;*sum&#125;&quot;); UnsafeUtility.Free(sum, Allocator.TempJob); &#125;&#125; 5. innerloopBatchCount官方说明：innerloopBatchCount是执行任务窃取的粒度。并在这个worker线程中连续调用innerloopBatchCount次的Execute(index)方法。当每次迭代中都有大量工作时，将值设为1是合理的。反之设置为32或64是合理的。 测试不同batchCount对性能的影响： 12345678910111213141516171819202122232425262728293031var job = new VelocityJob()&#123; deltaTime = Time.deltaTime, position = _positions, velocity = _velocity&#125;;var batchCount = 1;Profiler.BeginSample($&quot;Batch = &#123;batchCount&#125;&quot;);job.ScheduleParallel(_positions.Length, batchCount, new JobHandle()).Complete();Profiler.EndSample();batchCount = 8;Profiler.BeginSample($&quot;Batch = &#123;batchCount&#125;&quot;);job.ScheduleParallel(_positions.Length, batchCount, new JobHandle()).Complete();Profiler.EndSample();batchCount = 16;Profiler.BeginSample($&quot;Batch = &#123;batchCount&#125;&quot;);job.ScheduleParallel(_positions.Length, batchCount, new JobHandle()).Complete();Profiler.EndSample();batchCount = 32;Profiler.BeginSample($&quot;Batch = &#123;batchCount&#125;&quot;);job.ScheduleParallel(m_Positions.Length, batchCount, new JobHandle()).Complete();Profiler.EndSample();batchCount = 64;Profiler.BeginSample($&quot;Batch = &#123;batchCount&#125;&quot;);job.ScheduleParallel(_positions.Length, batchCount, new JobHandle()).Complete();Profiler.EndSample(); 如图： Batch=1时性能最差，Batch=8时性能稍好，当Batch为8的整数倍时，性能是相近的。出现这个现象的原因是伪共享。CPU缓存结构： 一个 CPU 里通常会有多个 CPU 核心，如上图中的 CPU1 和 CPU2，并且每个 CPU 核心都有自己的 L1 Cache 和 L2 Cache，而 L1 Cache 通常分为 DCache（数据缓存） 和 ICache（指令缓存），L3 Cache 则是多个核心共享的。 伪共享产生的原因： 由于缓存读取的机制，不是一次只读一个数据，而是一次读取一个CacheLine的数据。如果有两个CPU同时访问到内存中的同一个CachLine数据时，CacheLine会同时被加载进入CPU1和CPU2中。由于MESI协议，CPU1修改数据时，CPU2所共享的CacheLine将会失效，CPU2只能等到CPU1修改完后，再重新获取CacheLine并修改。这样就导致了CPU2运行效率的降低。这个问题就是false sharing。 Batch=1便是伪共享导致效率低下，分析Batch数为8的整数倍时运行效率几乎一样的原因： 123456789101112struct VelocityJob : IJobFor&#123; [ReadOnly] public NativeArray&lt;float3&gt; velocity; public NativeArray&lt;float3&gt; position; public float deltaTime; public void Execute(int i) &#123; position[i] += velocity[i] * deltaTime; &#125;&#125; velocity和position都是float3类型，大小是4 3 = 12字节，电脑的cache line大小是32字节，得出 12 8 == 32 * 3 == 96，因此当batch大小是8的倍数时恰好可以避免伪共享（false sharing）问题，因此时间几乎一致。 6. SoA vs AoSarray of structures (AoS)和structure of arrays (SoA)代表两种不同的数据组织形式： 123456789101112131415struct AoSData&#123; public int a; public int b; public int c; public int d;&#125;struct SoAData&#123; public NativeArray&lt;int&gt; aArray; public NativeArray&lt;int&gt; bArray; public NativeArray&lt;int&gt; cArray; public NativeArray&lt;int&gt; dArray;&#125; 内存布局： AoSData的数据a，b，c，d在内存中是交错存在的。而SoAData中相同的数据在内存中是连续存在的。两种形式对于数据访问的性能： 假设a，b，c，d四个数据的大小是一样的并且当前CPU的cache line一次可以加载4个数据即一个cache line可以加载a，b，c，d或者a，a，a，b四个数据。使用AoSData的情况下访问所有的a数据需要访问3次内存： 加载abcd，找到第一个a 加载abcd，找到第二个a 加载abcd，找到第三个a 使用SoAData只需要一次，加载aaab，找到三个a。且SoA对SIMD指令更加友好，Burst对SoA形式的数据也有特别的支持，都能让SoAData具有更好的性能，编码测试。 数据定义： 1234567891011121314// Unity中典型的AoS和SoA数据的组织形式public struct TransformAoS&#123; public float3 position; public quaternion rotation; public float3 scale;&#125;public class TransformSoA&#123; public NativeArray&lt;float3&gt; positions; public NativeArray&lt;quaternion&gt; rotations; public NativeArray&lt;float3&gt; scales;&#125; AoS的Job实现： 12345678910111213public struct TransformAoSJob : IJobFor&#123; public NativeArray&lt;TransformAoS&gt; transformAoSes; [ReadOnly] public float3 velocity; [ReadOnly] public float deltaTime; public void Execute(int index) &#123; var transAoS = transformAoSes[index]; transAoS.position += velocity * deltaTime; transformAoSes[index] = transAoS; &#125;&#125; var transAoS = transformAoSes[index]会产生一次结构体拷贝，结构体比较小的时候性能开销并不高，但是当结构体中数据量比较大的时候，开销也会升高。由于transAoS是一个拷贝副本，因此对它的修改不会反映在数据本体上，所以在Job的最后把拷贝出来的值又赋值回了transformAoSes数组，又产生了一次数据拷贝。利用指针来获取原始数据的引用改进代码： 1234567891011121314151617public struct TransformAoSJob : IJobFor&#123; public NativeArray&lt;TransformAoS&gt; transformAoSes; [ReadOnly] public float3 velocity; [ReadOnly] public float deltaTime; public void Execute(int index) &#123; // var transAoS = transformAoSes[index]; // transAoS.position += velocity * deltaTime; // transformAoSes[index] = transAoS; var transformPtr = (TransformAoS*)transformAoSes.GetUnsafePtr(); ref var transform = ref transformPtr[index]; transform.position += velocity * deltaTime; &#125;&#125; SoA的Job实现： 1234567891011public struct TransformSoAJob : IJobFor&#123; [NoAlias] public NativeArray&lt;float3&gt; positions; [ReadOnly] public float3 velocity; [ReadOnly] public float deltaTime; public void Execute(int index) &#123; positions[index] += velocity * deltaTime; &#125;&#125; 需要使用Burst编译，否则无差别，没使用BurstCompile的性能对比： BurstCompile性能对比： 完整代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135using System;using Unity.Burst;using Unity.Collections;using Unity.Collections.LowLevel.Unsafe;using Unity.Jobs;using Unity.Mathematics;using UnityEngine;using Random = Unity.Mathematics.Random;namespace JobSystem.SoA_VS_AoS&#123; public struct TransformAoS &#123; public float3 position; public quaternion rotation; public float3 scale; &#125; public unsafe class TransformBehaviour : MonoBehaviour &#123; public class TransformSoA : IDisposable &#123; public NativeArray&lt;float3&gt; positions; public NativeArray&lt;quaternion&gt; rotations; public NativeArray&lt;float3&gt; scales; public TransformSoA(int count) &#123; Create(count); &#125; private void Create(int count) &#123; positions = new NativeArray&lt;float3&gt;(count, Allocator.Persistent); rotations = new NativeArray&lt;quaternion&gt;(count, Allocator.Persistent); scales = new NativeArray&lt;float3&gt;(count, Allocator.Persistent); &#125; public void Dispose() &#123; if (positions.IsCreated) positions.Dispose(); if (rotations.IsCreated) rotations.Dispose(); if (scales.IsCreated) scales.Dispose(); &#125; &#125; [BurstCompile] public struct TransformAoSJob : IJobFor &#123; public NativeArray&lt;TransformAoS&gt; transformAoSes; [ReadOnly] public float3 velocity; [ReadOnly] public float deltaTime; public void Execute(int index) &#123; var transformPtr = (TransformAoS*)transformAoSes.GetUnsafePtr(); ref var transform = ref transformPtr[index]; transform.position += velocity * deltaTime; &#125; &#125; [BurstCompile] public struct TransformSoAJob : IJobFor &#123; public NativeArray&lt;float3&gt; positions; [ReadOnly] public float3 velocity; [ReadOnly] public float deltaTime; public void Execute(int index) &#123; var positionPtr = (float3*)positions.GetUnsafePtr(); ref var position = ref positionPtr[index]; position += velocity * deltaTime; &#125; &#125; private NativeArray&lt;TransformAoS&gt; m_TransformAoSes; private TransformSoA m_TransformSoA; private float3 m_Velocity; private static readonly int TRANSFORM_COUNT = 5000000; private void Start() &#123; m_TransformAoSes = new NativeArray&lt;TransformAoS&gt;(TRANSFORM_COUNT, Allocator.Persistent); m_TransformSoA = new TransformSoA(TRANSFORM_COUNT); var transformAoSPtr = (TransformAoS*)m_TransformAoSes.GetUnsafePtr(); var rand = new Random(1332); m_Velocity = rand.NextFloat3Direction(); for (int i = 0; i &lt; TRANSFORM_COUNT; i++) &#123; ref var transAoS = ref transformAoSPtr[i]; transAoS.position = rand.NextFloat3(); transAoS.rotation = rand.NextQuaternionRotation(); transAoS.scale = new float3(1, 1, 1); m_TransformSoA.positions[i] = rand.NextFloat3(); m_TransformSoA.rotations[i] = rand.NextQuaternionRotation(); m_TransformSoA.scales[i] = new float3(1, 1, 1); &#125; &#125; private void OnDestroy() &#123; m_TransformAoSes.Dispose(); m_TransformSoA.Dispose(); &#125; private void Update() &#123; new TransformSoAJob &#123; positions = m_TransformSoA.positions, velocity = m_Velocity, deltaTime = Time.deltaTime &#125;.ScheduleParallel(m_TransformSoA.positions.Length, 64, new JobHandle()).Complete(); new TransformAoSJob &#123; transformAoSes = m_TransformAoSes, velocity = m_Velocity, deltaTime = Time.deltaTime &#125;.ScheduleParallel(m_TransformAoSes.Length, 64, new JobHandle()).Complete(); &#125; &#125;&#125;","categories":[{"name":"Uniy","slug":"Uniy","permalink":"https://raoyuqi.github.io/categories/Uniy/"}],"tags":[{"name":"Uniy","slug":"Uniy","permalink":"https://raoyuqi.github.io/tags/Uniy/"},{"name":"Dots","slug":"Dots","permalink":"https://raoyuqi.github.io/tags/Dots/"}]},{"title":"颜色","slug":"graphic/opengl/颜色","date":"2023-08-07T13:20:14.000Z","updated":"2023-08-07T13:51:31.187Z","comments":false,"path":"2023/08/07/graphic/opengl/颜色/","link":"","permalink":"https://raoyuqi.github.io/2023/08/07/graphic/opengl/%E9%A2%9C%E8%89%B2/","excerpt":"","text":"1. 概述颜色空间有RGB、CMYK、LAB、HSV等，其中RGB是游戏中最常用的。它由红色(Red)、绿色(Green)和蓝色(Blue)三个分量组成，通常每个分量用8位存储，则rgb可表示2的24次方种颜色。用这三个值就可以组合出任意一种颜色，例如需要白色，可以定义如下颜色向量： 1glm::vec3 white(1.0f, 1.0f, 1.0f); 现实生活中能看到物体的颜色并不是物体真的由颜色，而是物体表面无法吸收而反射的颜色。太阳光是由多种不同颜色的光组成的白色，照射到红色物体后，它会吸收除了红色以外的所有颜色，不能吸收的将被反射，最后进入人眼，因此看到的都是物体反射的颜色，如下： 图形渲染中反射颜色： 123456// 白光glm::vec3 lightColor(1.0f, 1.0f, 1.0f);// 物体颜色反射系数glm::vec3 toyColor(1.0f, 0.0f, 0.0f);// 结果(1.0f, 0.0f, 0.0f);glm::vec3 result = lightColor * toyColor; 物体根据自身的颜色值对红、绿、蓝三个分量都做出了一定的反射，也表现了现实中颜色的工作原理。由此，可以定义物体的颜色为物体从一个光源反射各个颜色分量的大小。改变光照颜色也可以改变物体的颜色： 123456// 绿光glm::vec3 lightColor(0.0f, 1.0f, 0.0f);// 物体颜色反射系数glm::vec3 toyColor(1.0f, 0.0f, 0.0f);// 结果(0.0f, 0.0f, 0.0f);glm::vec3 result = lightColor * toyColor; 2. 创建光照场景光源的顶点着色器： 1234567891011#version 330 corelayout (location = 0) in vec3 aPos;uniform mat4 model;uniform mat4 view;uniform mat4 projection;void main()&#123; gl_Position = projection * view * model * vec4(aPos, 1.0);&#125; 光源的片段着色器，让它一直呈现白色： 12345678#version 330 coreout vec4 FragColor;void main()&#123; // 将向量的四个分量全部设置为1.0 FragColor = vec4(1.0);&#125; 物体的顶点着色器： 1234567891011#version 330 corelayout (location = 0) in vec3 aPos;uniform mat4 model;uniform mat4 view;uniform mat4 projection;void main()&#123; gl_Position = projection * view * model * vec4(aPos, 1.0);&#125; 物体的片段着色器： 12345678910#version 330 coreout vec4 FragColor;uniform vec3 objectColor;uniform vec3 lightColor;void main()&#123; FragColor = vec4(lightColor * objectColor, 1.0);&#125; 渲染光源： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 光源位置glm::vec3 lightPos(1.2f, 1.0f, 2.0f);...// 物体unsigned int VBO, cubeVAO;glGenVertexArrays(1, &amp;cubeVAO);glGenBuffers(1, &amp;VBO);glBindBuffer(GL_ARRAY_BUFFER, VBO);glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);glBindVertexArray(cubeVAO);glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);glEnableVertexAttribArray(0);// 光源unsigned int lightCubeVAO;glGenVertexArrays(1, &amp;lightCubeVAO);glBindVertexArray(lightCubeVAO);glBindBuffer(GL_ARRAY_BUFFER, VBO);glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);glEnableVertexAttribArray(0);...// 渲染物体cubeShader.use();cubeShader.setVec3(&quot;objectColor&quot;, 1.0f, 0.5f, 0.31f);cubeShader.setVec3(&quot;lightColor&quot;, 1.0f, 1.0f, 1.0f);glm::mat4 projection = glm::perspective(glm::radians(camera.Zoom), (float)SCR_WIDTH / (float)SCR_HEIGHT, 0.1f, 100.0f);glm::mat4 view = camera.GetViewMatrix();cubeShader.setMat4(&quot;projection&quot;, projection);cubeShader.setMat4(&quot;view&quot;, view);glm::mat4 model = glm::mat4(1.0f);cubeShader.setMat4(&quot;model&quot;, model);glBindVertexArray(cubeVAO);glDrawArrays(GL_TRIANGLES, 0, 36);// 渲染光源lightShader.use();cubeShader.setMat4(&quot;projection&quot;, projection);cubeShader.setMat4(&quot;view&quot;, view);model = glm::mat4(1.0f);model = glm::translate(model, lightPos);model = glm::scale(model, glm::vec3(0.2f));cubeShader.setMat4(&quot;model&quot;, model);glBindVertexArray(lightCubeVAO);glDrawArrays(GL_TRIANGLES, 0, 36); 效果：","categories":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://raoyuqi.github.io/tags/OpenGL/"}]},{"title":"摄像机","slug":"graphic/opengl/摄像机","date":"2023-07-29T02:12:24.000Z","updated":"2023-07-29T03:31:34.544Z","comments":false,"path":"2023/07/29/graphic/opengl/摄像机/","link":"","permalink":"https://raoyuqi.github.io/2023/07/29/graphic/opengl/%E6%91%84%E5%83%8F%E6%9C%BA/","excerpt":"","text":"1. 构建摄像机1.1 确定位置1glm::vec3 cameraPos = glm::vec3(0.0f, 0.0f, 3.0f); 1.2 确定z轴1234// 让摄像机指向场景原点glm::vec3 cameraTarget = glm::vec3(0.0f, 0.0f, 0.0f);// 向量相减，让相机的z轴正方向看向世界的z轴负方向glm::vec3 cameraDirection = glm::normalize(cameraPos - cameraTarget); 1.3 确定x轴1234// 先定义一个上向量glm::vec3 up = glm::vec3(0.0f, 1.0f, 0.0f);// y,z叉乘得到x轴正方向glm::vec3 cameraRight = glm::normalize(glm::cross(up, cameraDirection)); 1.4 确定y轴12// z,x叉乘得到y轴正方向glm::vec3 cameraUp = glm::cross(cameraDirection, cameraRight); 摄像机坐标系如图： 2. GLM构建观察空间矩阵123glm::mat4 view;// 传入摄像机位置，目标方向，和向上向量构建观察矩阵view = glm::lookAt(glm::vec3(0.0f, 0.0f, 3.0f), glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3(0.0f, 1.0f, 0.0f)); 实现相机绕原点旋转： 1234567// 半径float radius = 10.0f;// 画圆float camX = sin(glfwGetTime()) * radius;float camZ = cos(glfwGetTime()) * radius;glm::mat4 view;view = glm::lookAt(glm::vec3(camX, 0.0, camZ), glm::vec3(0.0, 0.0, 0.0), glm::vec3(0.0, 1.0, 0.0)); 效果： 3. 自由移动12345678910111213141516171819202122232425...glm::vec3 cameraPos = glm::vec3(0.0f, 0.0f, 3.0f);glm::vec3 cameraFront = glm::vec3(0.0f, 0.0f, -1.0f); // 看向z轴负方向glm::vec3 cameraUp = glm::vec3(0.0f, 1.0f, 0.0f);// 观察矩阵始终看向z轴负方向view = glm::lookAt(cameraPos, cameraPos + cameraFront, cameraUp);...// 监听键盘输入void processInput(GLFWwindow *window)&#123; ... float cameraSpeed = 0.05f; if (glfwGetKey(window, GLFW_KEY_W) == GLFW_PRESS) cameraPos += cameraSpeed * cameraFront; if (glfwGetKey(window, GLFW_KEY_S) == GLFW_PRESS) cameraPos -= cameraSpeed * cameraFront; if (glfwGetKey(window, GLFW_KEY_A) == GLFW_PRESS) cameraPos -= glm::normalize(glm::cross(cameraFront, cameraUp)) * cameraSpeed; // 减去叉乘得到x轴正方向，往左移动, normalize保证匀速 if (glfwGetKey(window, GLFW_KEY_D) == GLFW_PRESS) cameraPos += glm::normalize(glm::cross(cameraFront, cameraUp)) * cameraSpeed; // 加上叉乘得到x轴正方向，往右移动, normalize保证匀速&#125; 调整移动速度： 根据处理器的能力不同，不能保证不同设备每秒绘制相同帧数。导致配置的不同，有些人可能移动很快，而有些人会移动很慢。实现不同设备匀速： 1234567891011121314151617181920// 当前帧与上一帧的时间差float deltaTime = 0.0f;// 上一帧的时间float lastFrame = 0.0f;...float currentFrame = glfwGetTime();// 更新渲染当前帧花费的时间deltaTime = currentFrame - lastFrame;lastFrame = currentFrame;...void processInput(GLFWwindow *window)&#123; // 使用时间去平衡速度：帧率高的deltaTime小，速度慢，帧率低的deltaTime大，速度快 float cameraSpeed = 2.5f * deltaTime; ...&#125; 效果： 4. 视角移动4.1 欧拉角欧拉角(Euler Angle)是可以表示3D空间中任何旋转的3个值，由莱昂哈德·欧拉(Leonhard Euler)提出。一共有3种欧拉角：俯仰角(Pitch)、偏航角(Yaw)和滚转角(Roll)，如下图： 游戏中的摄像机比较少使用到滚转角，此处推导经过俯仰角和偏航角后摄像机的方向： 可得： 1234// 由相机初始看向x正半轴推导出来的相机新的方向direction.x = cos(glm::radians(pitch)) * cos(glm::radians(yaw));direction.y = sin(glm::radians(pitch));direction.z = cos(glm::radians(pitch)) * sin(glm::radians(yaw)); 可以用用旋转矩阵进行推导，出现结果不一致可参考链接。 4.2 鼠标输入通过鼠标的移动来控制镜头： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// 上一次鼠标位置float lastX = 400, lastY = 300;// 隐藏光标glfwSetInputMode(window, GLFW_CURSOR, GLFW_CURSOR_DISABLED);// 回调函数void mouse_callback(GLFWwindow* window, double xpos, double ypos);// 监听鼠标输入glfwSetCursorPosCallback(window, mouse_callback);void mouse_callback(GLFWwindow* window, double xpos, double ypos)&#123; // 防止首次抖动 if(firstMouse) &#123; lastX = xpos; lastY = ypos; firstMouse = false; &#125; // 计算x,y偏移 float xoffset = xpos - lastX; float yoffset = lastY - ypos; lastX = xpos; lastY = ypos; // 灵敏度 float sensitivity = 0.05; // 偏移乘上灵敏系数，获得合适的改变幅度 xoffset *= sensitivity; yoffset *= sensitivity; // 将偏移加到仰俯，偏航角上 yaw += xoffset; pitch += yoffset; // 限制极限情况(在90度时视角会发生逆转) if(pitch &gt; 89.0f) pitch = 89.0f; if(pitch &lt; -89.0f) pitch = -89.0f; // 使用公式计算新的相机方向 glm::vec3 front; front.x = cos(glm::radians(yaw)) * cos(glm::radians(pitch)); front.y = sin(glm::radians(pitch)); front.z = sin(glm::radians(yaw)) * cos(glm::radians(pitch)); cameraFront = glm::normalize(front);&#125; 4.3 缩放缩放的原理是改变fov视野大小，当视野变小时，场景投影出来的空间就会减小，产生放大的感觉，视野变大则相反，代码： 12345678910111213141516171819void scroll_callback(GLFWwindow* window, double xoffset, double yoffset)// 监听鼠标滚轮输入glfwSetScrollCallback(window, scroll_callback);void scroll_callback(GLFWwindow* window, double xoffset, double yoffset)&#123; if(fov &gt;= 1.0f &amp;&amp; fov &lt;= 45.0f) fov -= yoffset; if(fov &lt;= 1.0f) fov = 1.0f; if(fov &gt;= 45.0f) fov = 45.0f;&#125;// 更新投影矩阵的视野projection = glm::perspective(glm::radians(fov), 800.0f / 600.0f, 0.1f, 100.0f); 效果： 5. 摄像机类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140#ifndef CAMERA_H#define CAMERA_H#include &lt;glad/glad.h&gt;#include &lt;glm/glm.hpp&gt;#include &lt;glm/detail/type_vec.hpp&gt;#include &lt;glm/gtc/matrix_transform.hpp&gt;// 相机移动方向enum Camera_Movement &#123; FORWARD, BACKWARD, LEFT, RIGHT&#125;;// 默认偏航角// 由于公式用的初态相机位置看向x轴正方向，因此偏航-90度，让相机看向z轴负方向const float YAW = -90.0f;// 默仰俯角const float PITCH = 0.0f;// 默认移动速度const float SPEED = 3.0f;// 默认鼠标灵敏系数，影响旋转const float SENSITIVITY = 0.05f;// 默认缩放视野const float ZOOM = 45.0f;class Camera&#123;public: // 位置 glm::vec3 Position; // 向前方向 z轴 glm::vec3 Front; // 向上方向 y轴 glm::vec3 Up; // 向右方向 x轴 glm::vec3 Right; // 世界的上方向 glm::vec3 WorldUp; // 欧拉角 float Yaw; float Pitch; // 其它属性 float MovementSpeed; float MouseSensitivity; double Zoom; // 构造函数 Camera(glm::vec3 position = glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3 up = glm::vec3(0.0f, 1.0f, 0.0f), float yaw = YAW, float pitch = PITCH) : Front(glm::vec3(0.0f, 0.0f, -1.0f)), MovementSpeed(SPEED), MouseSensitivity(SENSITIVITY), Zoom(ZOOM) &#123; Position = position; WorldUp = up; Yaw = yaw; Pitch = pitch; updateCameraVectors(); &#125; Camera(float posX, float posY, float posZ, float upX, float upY, float upZ, float yaw, float pitch) : Front(glm::vec3(0.0f, 0.0f, -1.0f)), MovementSpeed(SPEED), MouseSensitivity(SENSITIVITY), Zoom(ZOOM) &#123; Position = glm::vec3(posX, posY, posZ); WorldUp = glm::vec3(upX, upY, upZ); Yaw = yaw; Pitch = pitch; updateCameraVectors(); &#125; // 返回使用欧拉角的观察矩阵 glm::mat4 GetViewMatrix() &#123; return glm::lookAt(Position, Position + Front, Up); &#125; // 键盘回调 void ProcessKeyboard(Camera_Movement direction, float deltaTime) &#123; float velocity = MovementSpeed * deltaTime; if (direction == FORWARD) Position += Front * velocity; if (direction == BACKWARD) Position -= Front * velocity; if (direction == LEFT) Position -= Right * velocity; if (direction == RIGHT) Position += Right * velocity; &#125; // 鼠标回调 void ProcessMouseMovement(float xoffset, float yoffset, GLboolean constrainPitch = true) &#123; xoffset *= MouseSensitivity; yoffset *= MouseSensitivity; Yaw += xoffset; Pitch += yoffset; // 限制 if (constrainPitch) &#123; if (Pitch &gt; 89.0f) Pitch = 89.0f; if (Pitch &lt; -89.0f) Pitch = -89.0f; &#125; // 使用更新的Euler角度更新“前向量”、“右向量”和“上向量” updateCameraVectors(); &#125; // 鼠标滚轮回调 void ProcessMouseScroll(float yoffset) &#123; Zoom -= (float)yoffset; if (Zoom &lt; 1.0f) Zoom = 1.0f; if (Zoom &gt; 100.0f) Zoom = 100.0f; &#125;private: // 根据摄影机的（更新的）欧拉角计算前向量 void updateCameraVectors() &#123; glm::vec3 front; front.x = cos(glm::radians(Yaw)) * cos(glm::radians(Pitch)); front.y = sin(glm::radians(Pitch)); front.z = sin(glm::radians(Yaw)) * cos(glm::radians(Pitch)); Front = glm::normalize(front); // 同时重新计算向右和向上矢量 // 对向量进行归一化，因为向上或向下看得越多，它们的长度就越接近0，这会导致移动速度变慢 Right = glm::normalize(glm::cross(Front, WorldUp)); Up = glm::normalize(glm::cross(Right, Front)); &#125;&#125;;#endif 6. 扩展阅读如何将欧拉角转换为方向向量 欧拉角导致万向锁原因 欧拉角与万向死锁","categories":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://raoyuqi.github.io/tags/OpenGL/"}]},{"title":"坐标","slug":"graphic/opengl/坐标","date":"2023-07-26T13:53:31.000Z","updated":"2023-07-26T14:20:18.946Z","comments":false,"path":"2023/07/26/graphic/opengl/坐标/","link":"","permalink":"https://raoyuqi.github.io/2023/07/26/graphic/opengl/%E5%9D%90%E6%A0%87/","excerpt":"","text":"1. 概述对物体的不同操作有不同的意义，你如：当需要对物体进行修改的时候，在局部空间中操作会比较合理；如果要对一个物体做出一个相对于其它物体位置的操作时，在世界坐标系中更合理，等等。因此也衍生出了不同的坐标空间。 2. 坐标空间 局部空间 物体所在的坐标空间，即对象最开始所在的地方。建模软件中创建了一个立方体，立方体的原点有可能位于(0, 0, 0)，有可能创建的所有模型都以(0, 0, 0)为初始位置，然而它们会最终出现在世界的不同位置。所以，模型的所有顶点都是在局部空间中：它们相对于物体来说都是局部的。 世界空间 指顶点相对于游戏世界的坐标。如果希望将物体分散在世界上摆放，就需要将物体变换到世界空间。该变换是由模型矩阵(Model Matrix)实现的。模型矩阵能通过对物体进行位移、缩放、旋转来将它置于它本应该在的位置或朝向。经过模型矩阵变换后，物体的坐标将会从局部变换到世界空间。 观察空间 以摄像机为视角观察到的空间，因此也称摄像机空间。观察空间是将世界空间坐标转化为用户视野前方的坐标而产生的结果，因此观察空间就是从摄像机的视角所观察到的空间。改变换由观察矩阵(View Matrix)实现。 裁剪空间 OpenGL希望所有的坐标都在一个特定的范围内，所有不在范围内的顶点都会被裁剪丢弃，剩下才会进行处理，节省不必要的消耗。将顶点从观察空间变换到裁剪空间需要使用投影矩阵。指定了一个坐标范围，如：-100到100，投影矩阵会将该指定范围转换为标准化设备的范围(-1.0, 1.0)。所有在(-1.0, 1.0)之外的顶点都会被裁剪，比如顶点坐标为(80, 101)会被裁剪，因为转换后y坐标超出了范围，应该丢弃。 如果只是图元(Primitive)，例如三角形，的一部分超出了裁剪体积(Clipping Volume)，则OpenGL会重新构建这个三角形为一个或多个三角形让它能够适合这个裁剪范围。 由投影矩阵创建的观察箱(Viewing Box)被称为平截头体(Frustum)，每个出现在平截头体范围内的坐标都会最终出现在用户的屏幕上。将特定范围内的坐标转化到标准化设备坐标系的过程被称之为投影(Projection)。 当所有顶点被变换到裁剪空间，会执行透视除法，在这个过程中做的就是将位置向量的x，y，z分量分别除以向量的齐次w分量；目的是把4D裁剪空间的齐次坐标变换为3D标准化设备坐标。这一步会在每一个顶点着色器运行的最后被自动执行。 在这一阶段之后，最终的坐标将会被映射到屏幕空间中（即glViewport中的设定），并被变换成片段。投影矩阵有两种： 正交投影 正交投影定义了一个类似立方体的平截头箱，它定义了一个裁剪空间，在这空间之外的顶点都会被裁剪掉。创建一个正射投影矩阵需要指定可见平截头体的宽、高和长度。上面的平截头体定义了可见的坐标，它由由宽、高、近(Near)平面和远(Far)平面所指定。任何出现在近平面之前或远平面之后的坐标都会被裁剪掉。 由于每个向量的w分量都没有进行改变（w分量等于1.0），因此透视除法后坐标不变，出现的视觉效果是，进出的物体和远处的物体大小一致，造成不真实感。 GLM创建正交投影矩阵： 1234// 前两个参数指定了平截头体的左右坐标，第三和第四参数指定了平截头体的底部和顶部// 通过这四个参数定义近平面和远平面的大小，然后第五和第六个参数则定义了近平面和远平面的距离// 这个投影矩阵会将处于这些x，y，z值范围内的坐标变换为标准化设备坐标glm::ortho(0.0f, 800.0f, 0.0f, 600.0f, 0.1f, 100.0f); 透视投影 现实生活中近大远小的现象称为透视，要实现透视效果需要使用透视投影矩阵来完成。透视投影矩阵将给定的平截头体范围映射到裁剪空间，还会修改每个顶点坐标的w值，从而使得离观察者越远的顶点坐标w分量越大。被变换到裁剪空间的坐标都会在-w到w的范围之间（任何不在这个范围的坐标都会被裁剪掉）。OpenGL对在范围内的顶点进行透视除法操作： $out=\\begin{pmatrix} x/w \\\\ y/w \\\\ z/w \\end{pmatrix}$ 由于越远的物体w分量越大，因此模拟除了透视效果，这是w重要用途之一。 GLM创建透视投影矩阵： 1234// 第一个参数定义了fov的值，表示的是视野(Field of View)，想要一个真实的观察效果，它的值通常设置为45.0f，但想要一个末日风格的结果你可以将其设置一个更大的值// 第二个参数设置了宽高比，由视口的宽除以高所得// 第三和第四个参数设置了平截头体的近和远平面。通常设置近距离为0.1f，而远距离设为100.0f。所有在近平面和远平面内且处于平截头体内的顶点都会被渲染glm::mat4 proj = glm::perspective(glm::radians(45.0f), (float)width/(float)height, 0.1f, 100.0f); 当你把透视矩阵的 near 值设置太大时（如10.0f），OpenGL会将靠近摄像机的坐标（在0.0f和10.0f之间）都裁剪掉，这会导致在游戏中的视觉效果：太过靠近一个物体的时候你的视线会直接穿过去。 由于正交投影没有使用透视，远处的物体不会显得更小，所以正射投影主要用于二维渲染以及一些建筑或工程的程序，在这些场景中更希望顶点不会被透视所干扰。 屏幕空间 顶点着色器的输出要求所有的顶点都在裁剪空间内，因此先将顶点从局部空间转换到裁剪空间： $V_{clip}=M_{projection} \\cdot M_{view} \\cdot M_{model} \\cdot V_{local}$ 转换到裁剪空间后，最后会将结果赋值给顶点着色器的gl_Position，OpenGL将会自动进行透视除法和裁剪操作。 OpenGL接着会对裁剪坐标执行透视除法将它们变换到标准化设备坐标。OpenGL使用glViewPort内部的参数将标准化设备坐标映射到屏幕坐标，每个坐标都关联了一个屏幕上的点，这个过程称为视口变换。 物体变换过程： 局部坐标是对象相对于局部原点的坐标，是物体起始的坐标 将局部坐标变换为世界空间坐标，这些坐标相对于世界的全局原点，它们会和其它物体一起相对于世界的原点进行摆放 将世界坐标变换为观察空间坐标，使得每个坐标都是从摄像机或者说观察者的角度进行观察的 坐标到达观察空间之后，需要将其投影到裁剪坐标。裁剪坐标会被处理至-1.0到1.0的范围内，并判断哪些顶点将会出现在屏幕上 最后将裁剪坐标变换为屏幕坐标，这是视口变换(Viewport Transform)的过程。视口变换将位于-1.0到1.0范围的坐标变换到由glViewport函数所定义的坐标范围内。最后变换出来的坐标将会送到光栅器，将其转化为片段 3. 实现3D效果1234567891011121314151617181920212223// 创建模型矩阵// 绕x轴旋转-55度glm::mat4 model;model = glm::rotate(model, glm::radians(-55.0f), glm::vec3(1.0f, 0.0f, 0.0f));// 创建观察矩阵// 往z轴正方向平移3个单位glm::mat4 view;view = glm::translate(view, glm::vec3(0.0f, 0.0f, -3.0f));// 创建透视投影矩阵glm::mat4 projection;projection = glm::perspective(glm::radians(45.0f), screenWidth / screenHeight, 0.1f, 100.0f);// 将矩阵传递到顶点着色器中int modelLoc = glGetUniformLocation(shader.ID, &quot;model&quot;));glUniformMatrix4fv(modelLoc, 1, GL_FALSE, glm::value_ptr(model));int viewLoc = glGetUniformLocation(shader.ID, &quot;view&quot;));glUniformMatrix4fv(viewLoc, 1, GL_FALSE, glm::value_ptr(view));int projectionLoc = glGetUniformLocation(shader.ID, &quot;model&quot;));glUniformMatrix4fv(projectionLoc, 1, GL_FALSE, glm::value_ptr(projection)); 顶点着色器： 12345678910111213#version 330 corelayout (location = 0) in vec3 aPos;...uniform mat4 model;uniform mat4 view;uniform mat4 projection;void main()&#123; // 将顶点变换到裁剪空间中，矩阵乘法要从右向左 gl_Position = projection * view * model * vec4(aPos, 1.0); ...&#125; 效果： 3D立方体 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// 36个顶点数据，包含顶点坐标和纹理float vertices[] = &#123; -0.5f, -0.5f, -0.5f, 0.0f, 0.0f, 0.5f, -0.5f, -0.5f, 1.0f, 0.0f, 0.5f, 0.5f, -0.5f, 1.0f, 1.0f, 0.5f, 0.5f, -0.5f, 1.0f, 1.0f, -0.5f, 0.5f, -0.5f, 0.0f, 1.0f, -0.5f, -0.5f, -0.5f, 0.0f, 0.0f, -0.5f, -0.5f, 0.5f, 0.0f, 0.0f, 0.5f, -0.5f, 0.5f, 1.0f, 0.0f, 0.5f, 0.5f, 0.5f, 1.0f, 1.0f, 0.5f, 0.5f, 0.5f, 1.0f, 1.0f, -0.5f, 0.5f, 0.5f, 0.0f, 1.0f, -0.5f, -0.5f, 0.5f, 0.0f, 0.0f, -0.5f, 0.5f, 0.5f, 1.0f, 0.0f, -0.5f, 0.5f, -0.5f, 1.0f, 1.0f, -0.5f, -0.5f, -0.5f, 0.0f, 1.0f, -0.5f, -0.5f, -0.5f, 0.0f, 1.0f, -0.5f, -0.5f, 0.5f, 0.0f, 0.0f, -0.5f, 0.5f, 0.5f, 1.0f, 0.0f, 0.5f, 0.5f, 0.5f, 1.0f, 0.0f, 0.5f, 0.5f, -0.5f, 1.0f, 1.0f, 0.5f, -0.5f, -0.5f, 0.0f, 1.0f, 0.5f, -0.5f, -0.5f, 0.0f, 1.0f, 0.5f, -0.5f, 0.5f, 0.0f, 0.0f, 0.5f, 0.5f, 0.5f, 1.0f, 0.0f, -0.5f, -0.5f, -0.5f, 0.0f, 1.0f, 0.5f, -0.5f, -0.5f, 1.0f, 1.0f, 0.5f, -0.5f, 0.5f, 1.0f, 0.0f, 0.5f, -0.5f, 0.5f, 1.0f, 0.0f, -0.5f, -0.5f, 0.5f, 0.0f, 0.0f, -0.5f, -0.5f, -0.5f, 0.0f, 1.0f, -0.5f, 0.5f, -0.5f, 0.0f, 1.0f, 0.5f, 0.5f, -0.5f, 1.0f, 1.0f, 0.5f, 0.5f, 0.5f, 1.0f, 0.0f, 0.5f, 0.5f, 0.5f, 1.0f, 0.0f, -0.5f, 0.5f, 0.5f, 0.0f, 0.0f, -0.5f, 0.5f, -0.5f, 0.0f, 1.0f&#125;;// 修改模型矩阵，让立方体随时间旋转model = glm::rotate(model, (float)glfwGetTime() * glm::radians(20.0f), glm::vec3(0.5f, 1.0f, 0.0f));// 开启深度缓冲glEnable(GL_DEPTH_TEST);// 在每次渲染迭代之前清除深度缓冲，否则前一帧的深度信息仍然保存在缓冲中glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);// 绘制glDrawArrays(GL_TRIANGLES, 0, 36); 效果： 5. 更多立方体12345678910111213141516171819202122232425262728// 每个立方体的位置glm::vec3 cubePositions[] = &#123; glm::vec3( 0.0f, 0.0f, 0.0f), glm::vec3( 2.0f, 5.0f, -15.0f), glm::vec3(-1.5f, -2.2f, -2.5f), glm::vec3(-3.8f, -2.0f, -12.3f), glm::vec3( 2.4f, -0.4f, -3.5f), glm::vec3(-1.7f, 3.0f, -7.5f), glm::vec3( 1.3f, -2.0f, -2.5f), glm::vec3( 1.5f, 2.0f, -2.5f), glm::vec3( 1.5f, 0.2f, -1.5f), glm::vec3(-1.3f, 1.0f, -1.5f) &#125;;...glBindVertexArray(VAO);for(unsigned int i = 0; i &lt; 10; i++)&#123; // 赋予不同的模型矩阵 glm::mat4 model; model = glm::translate(model, cubePositions[i]); float angle = 20.0f * i; model = glm::rotate(model, glm::radians(angle), glm::vec3(1.0f, 0.3f, 0.5f)); ourShader.setMat4(&quot;model&quot;, model); glDrawArrays(GL_TRIANGLES, 0, 36);&#125; 效果：","categories":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://raoyuqi.github.io/tags/OpenGL/"}]},{"title":"变换","slug":"graphic/opengl/变换","date":"2023-07-25T13:32:02.000Z","updated":"2023-07-26T13:52:25.161Z","comments":false,"path":"2023/07/25/graphic/opengl/变换/","link":"","permalink":"https://raoyuqi.github.io/2023/07/25/graphic/opengl/%E5%8F%98%E6%8D%A2/","excerpt":"","text":"1. 向量既有大小又有方向的量，称为向量。向量相等的依据：方向相同且大小相等，如下图起点不同的两个向量 $\\vec{v}$ 和 $\\vec{w}$ 是相等的： 向量数学表示：$\\vec{v}=\\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix}$ 2. 向量运算2.1 向量与标量$\\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} + 1 = \\begin{pmatrix} x+1 \\\\ y+1 \\\\ z+1 \\end{pmatrix}$ 2.2 向量取反$-\\vec{v}=-\\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix}=\\begin{pmatrix} -x \\\\ -y \\\\ -z \\end{pmatrix}$ 2.3 向量加减$\\vec{v}+\\vec{w}=\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}+\\begin{pmatrix} 4 \\\\ 5 \\\\ 6 \\end{pmatrix}=\\begin{pmatrix} 5 \\\\ 7 \\\\ 9 \\end{pmatrix}$ $\\vec{v}-\\vec{w}=\\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}-\\begin{pmatrix} 4 \\\\ 5 \\\\ 6 \\end{pmatrix}=\\begin{pmatrix} -3 \\\\ -3 \\\\ -3 \\end{pmatrix}$ 2.4 向量长度和单位向量向量长度：$||\\vec{v}||=\\sqrt{x^2+y^2}$ 单位向量：$\\widehat{n} = \\frac{\\vec{v}}{||\\vec{v}||}$ 2.4 向量相乘 点乘 $\\vec{v} \\cdot \\vec{w} = ||\\vec{v}|| \\cdot ||\\vec{w}|| \\cdot \\cos\\vartheta$ 两个单位向量的点乘结果为两个向量的夹角：$\\vec{v} \\cdot \\vec{w} = 1 \\cdot 1 \\cdot \\cos\\vartheta = \\cos\\vartheta$ 几何意义：判断两个向量方向的相似性，即两个向量是否垂直、平行、方向相反等。 点乘计算：$\\begin{pmatrix} 1 \\\\ -1 \\\\ 0 \\end{pmatrix} \\cdot \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = (0.6 * 0) + (-1 * 1) + (0 * 0) = -1$，反余弦可得两向量夹角180度，方向相反。 叉乘 叉乘会生成一个垂直于两个向量的新向量，叉乘可以用来判断两个向量的位置关系，即一个向量是在另一个向量的右边还是左边。 叉乘计算：$\\begin{pmatrix} A_x \\\\ A_y \\\\ A_z \\end{pmatrix} \\cdot \\begin{pmatrix} B_x \\\\ B_y \\\\ B_z \\end{pmatrix} = \\begin{pmatrix} A_y \\cdot B_z-A_z \\cdot B_y \\\\ A_z \\cdot B_x-A_x \\cdot B_z \\\\ A_x \\cdot B_y-A_y \\cdot B_x \\end{pmatrix}$ 3. 矩阵矩阵就是一个矩形的数字、符号或表达式数组，矩阵中每一项叫做矩阵的元素。 3.1 矩阵相乘条件： 左侧矩阵的列数与右侧矩阵的行数相等，两个矩阵才能相乘 矩阵相乘不遵守交换律，$A \\cdot B \\not= B \\cdot A$ 例： $\\left[\\begin{matrix} 1 &amp; 2 \\\\ 3 &amp; 4 \\\\ \\end{matrix}\\right] \\cdot \\left[\\begin{matrix} 5 &amp; 6 \\\\ 7 &amp; 8 \\\\ \\end{matrix}\\right]=\\left[\\begin{matrix} 1 \\cdot 5+2 \\cdot 7 &amp; 1 \\cdot 6+2 \\cdot 8 \\\\ 3 \\cdot 5+4 \\cdot 7 &amp; 3 \\cdot 6+4 \\cdot 8 \\\\ \\end{matrix}\\right]=\\left[\\begin{matrix} 19 &amp; 22 \\\\ 43 &amp; 50 \\\\ \\end{matrix}\\right]$ 3.2 矩阵乘以向量矩阵可以用来变换向量： 缩放 $\\left[\\begin{matrix} S_1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; S_2 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; S_3 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ \\end{matrix}\\right] \\cdot \\left(\\begin{matrix} x \\\\ y \\\\ z \\\\ w \\\\ \\end{matrix}\\right)=\\left(\\begin{matrix} S_1 \\cdot x \\\\ S_2 \\cdot y \\\\ S_3 \\cdot z \\\\ w \\\\ \\end{matrix}\\right)$ 平移 $\\left[\\begin{matrix} 1 &amp; 0 &amp; 0 &amp; T_x \\\\ 0 &amp; 1 &amp; 0 &amp; T_y \\\\ 0 &amp; 0 &amp; 1 &amp; T_z \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ \\end{matrix}\\right] \\cdot \\left(\\begin{matrix} x \\\\ y \\\\ z \\\\ 1 \\\\ \\end{matrix}\\right)=\\left(\\begin{matrix} x+T_x \\\\ y+T_y \\\\ z+T_z \\\\ 1 \\\\ \\end{matrix}\\right)$ 向量的w分量也叫齐次坐标，可以把x、y和z坐标分别除以w坐标从而将其次坐标转换为3D向量。如果w分类为1，则表示的是坐标，如果w分量为0，则表示的是向量。 其次坐标的一个主要用途是将平移操作由仿射变换转换为线性变换。 旋转 绕x轴：$\\left[\\begin{matrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; \\cos\\vartheta &amp; -\\sin\\vartheta &amp; 0 \\\\ 0 &amp; \\sin\\vartheta &amp; \\cos\\vartheta &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ \\end{matrix}\\right]$ 绕y轴：$\\left[\\begin{matrix} \\cos\\vartheta &amp; 0 &amp; \\sin\\vartheta &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ -\\sin\\vartheta &amp; 0 &amp; \\cos\\vartheta &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ \\end{matrix}\\right]$ 绕z轴：$\\left[\\begin{matrix} \\cos\\vartheta &amp; -\\sin\\vartheta &amp; 0 &amp; 0 \\\\ \\sin\\vartheta &amp; \\cos\\vartheta &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ \\end{matrix}\\right]$ 3.3 矩阵组合将多个矩阵相乘可以将多个变换组合到一个矩阵中，比如先缩放再平移：$M=Trans \\cdot Scale -&gt; Trans \\cdot Scale \\cdot \\vec{v}=M \\cdot \\vec{v}$，矩阵相乘时，最右边的矩阵会先和向量相乘，所以这边表示的操作是先缩放后平移。 4. GLMGLM是OpenGL Mathematics的缩写，这是一个OpenGL数学库，点击链接进行下载，然后把头文件的根目录复制到includes文件夹就可以使用了，这里用的是低于0.99版本的GLM。 使用GLM库进行平移操作： 1234567891011#include &lt;glm/glm.hpp&gt;#include &lt;glm/gtc/matrix_transform.hpp&gt;#include &lt;glm/gtc/type_ptr.hpp&gt;// 创建一个向量glm::vec4 vec(1.0f, 0.0f, 0.0f, 1.0f);// 创建一个平移矩阵，平移(1, 1, 0)个单位glm::mat4 trans;trans = glm::translate(trans, glm::vec3(1.0f, 1.0f, 0.0f));// 平移操作vec = trans * vec; 将变换应用到图形中： 1234567891011// 创建一个矩阵glm::mat4 trans;// 绕z轴逆时针旋转90度，glm::radians将角度转化为弧度trans = glm::rotate(trans, glm::radians(90.0f), glm::vec3(0.0, 0.0, 1.0));// 缩放0.5倍trans = glm::scale(trans, glm::vec3(0.5, 0.5, 0.5));// 把矩阵传递给顶点着色器unsigned int transformLoc = glGetUniformLocation(shader.ID, &quot;transform&quot;);// GLM的默认布局就是列主序，所以并不需要转置矩阵glUniformMatrix4fv(transformLoc, 1, GL_FALSE, glm::value_ptr(trans)); 顶点着色器： 123456789101112131415#version 330 corelayout (location = 0) in vec3 aPos;layout (location = 1) in vec2 aTexCoord;out vec2 TexCoord;// 矩阵uniform mat4 transform;void main()&#123; // 变换操作 gl_Position = transform * vec4(aPos, 1.0f); TexCoord = vec2(aTexCoord.x, 1.0 - aTexCoord.y);&#125; 运行程序： 让矩形随着时间进行旋转： 123glm::mat4 trans;trans = glm::translate(trans, glm::vec3(0.5f, -0.5f, 0.0f));trans = glm::rotate(trans, (float)glfwGetTime(), glm::vec3(0.0f, 0.0f, 1.0f)); 矩阵的乘法是从右往左的，因此这里会先绕(0, 0, 1)旋转，然后再平移到屏幕右下角，虽然在逻辑上是先平移后旋转。 运行程序： 5. 扩展阅读线性代数本质：中文字幕版本","categories":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://raoyuqi.github.io/tags/OpenGL/"}]},{"title":"纹理","slug":"graphic/opengl/纹理","date":"2023-07-21T12:56:56.000Z","updated":"2023-07-21T13:20:03.668Z","comments":false,"path":"2023/07/21/graphic/opengl/纹理/","link":"","permalink":"https://raoyuqi.github.io/2023/07/21/graphic/opengl/%E7%BA%B9%E7%90%86/","excerpt":"","text":"1. 纹理的作用通过给顶点输入颜色数据可以让顶点显示指定的颜色，如果想渲染出更真实的图形，那么就需要足够多的顶点数据和颜色数据才能实现，这样开销很大。使用纹理可以解决这个问题。 纹理通常是一张2D图片（也有1D和3D的），是存储物体细节的容器，可以将物体需要的细节数据存储在纹理中，渲染的时候从纹理中采样出所需要的数据，这样就可以让物体非常的同时也不用添加大量的顶点数据。相当于把纹理贴到物体表面，这样物体就有了该纹理的外观，如下图： 想要把纹理映射到三角形上，需要指定每个三角形的每个顶点对应纹理的哪个部分，让每个顶点和纹理坐标关联起来，表示每个顶点该从纹理的哪个部分采样。纹理坐标的范围在0到1之间，使用纹理坐标获取纹理颜色叫做采样(Sampling)。纹理坐标起始于(0, 0)，终始于(1, 1)，下图展示了怎样将纹理映射到三角形： 纹理映射只要给顶点着色器传递纹理坐标就行，它们会被传片段着色器中，片段着色器中会为每个片段进行纹理坐标的插值。 2. 环绕方式纹理坐标范围从(0, 0)到(1, 1)，假设把纹理坐标设置在这个范围之外，应该如何表现？OpenGL提供了以下表现形式： GL_REPEAT: 重复纹理图像 GL_MIRRORED_REPEAT: 镜像重复 GL_CLAMP_TO_EDGE: 超出的部分会重复纹理坐标的边缘，产生边缘被拉伸的效果 GL_CLAMP_TO_BORDER: 超出的坐标为自定义的边缘颜色 视觉效果如下图： 设置代码： 1234567// 设置s(x)轴超出镜像重复glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_MIRRORED_REPEAT);// 设置t(y)轴超出镜像重复glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_MIRRORED_REPEAT);// 指定颜色float borderColor[] = &#123; 1.0f, 1.0f, 0.0f, 1.0f &#125;;glTexParameterfv(GL_TEXTURE_2D, GL_TEXTURE_BORDER_COLOR, borderColor); 3. 过滤纹理是由纹理像素组成，而采样的时候使用的是纹理坐标，所以OpenGL需要知道怎样将纹理像素映射到纹理坐标。有了映射方法才能够根据纹理坐标去查找纹理图像上的像素，然后进行采样提取纹理像素的颜色，最终显示。这里会有一些问题： 纹理分辨率很小：图像上的多个像素在渲染时取纹理映射上取到了同一个点，会有明显的方块状 纹理分辨率过大：图像上的一个像素覆盖的多个纹素，远处出现摩尔纹，进出出现锯齿 因此，需要一些过滤方法进行处理，纹理过滤最重要的两种： GL_NEAREST 邻近过滤，OpenGL的默认过滤方式，当设置为GL_NEAREST的时候，OpenGL会选择中心点最接近纹理坐标的那个像素，如下图： GL_LINEAR 线性过滤，选取纹理坐标附近的n个纹理像素使用插值方法，进行颜色混合。一个纹理像素的中心距离纹理坐标越近对最终的样本颜色的贡献越大，如下图： 两种方式的效果： 线性过滤更够生成更加平滑的效果，通常在图片被放大后可以设置为线性过滤，而初始状态或者别缩小可以设置为邻近过滤节省性能，设置代码： 12glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); 4. Mipmap在透视投影下，远处的物体会更小，如果这时候让它们使用和近处分辨率一样大的纹理，则不合适。由于远处的物体只产生很少的片段，而纹理分辨率太高，导致一个片段会跨越大范围纹理（即像素覆盖一片纹理区域）， 因此OpenGL很难对该片段只拾取一个纹理颜色，导致在小物体上这会产生不真实的感觉；同时高分辨率占用的内存也大，在远处物体上造成内存浪费。 OpenGL使用多级渐远纹理(Mipmap)解决该问题，Mipmap是一系列的纹理图像，后一个纹理图像是前一个的二分之一。思想：对不同距离的物体，使用不同的多级渐远纹理。同时，多级渐远纹理的性能也很好，Mipmap占用内存只是原始纹理的1.33倍，Mipmap如下： OpenGL创建Mipmap： 123glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR_MIPMAP_LINEAR);// 不要将放大的操作设置为Mipmap的过滤选项，这回产生异常，因为纹理放大不会使用MipmapglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); 5. 纹理的加载与创建5.1 加载纹理Sean Barrett的一个非常流行的单头文件图像加载库，下载链接。加载图片： 123456#define STB_IMAGE_IMPLEMENTATION#include &quot;stb_image.h&quot;// 宽高和颜色通道int width, height, nrChannels;unsigned char *data = stbi_load(&quot;image.jpg&quot;, &amp;width, &amp;height, &amp;nrChannels, 0); 5.2 创建纹理1234567891011121314151617181920// 创建1个纹理unsigned int texture;glGenTextures(1, &amp;texture);// 绑定glBindTexture(GL_TEXTURE_2D, texture);// 为当前绑定的纹理对象设置环绕、过滤方式glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);// 使用纹理数据生成纹理glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, data);// 生成MipmapglGenerateMipmap(GL_TEXTURE_2D);// 释放数据stbi_image_free(data); 5.3 应用纹理12345678// 在顶点数据中添加纹理坐标用来告诉OpenGL如何对纹理进行采样float vertices[] = &#123;// ---- 位置 ---- ---- 颜色 ---- - 纹理坐标 - 0.5f, 0.5f, 0.0f, 1.0f, 0.0f, 0.0f, 1.0f, 1.0f, // 右上 0.5f, -0.5f, 0.0f, 0.0f, 1.0f, 0.0f, 1.0f, 0.0f, // 右下 -0.5f, -0.5f, 0.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, // 左下 -0.5f, 0.5f, 0.0f, 1.0f, 1.0f, 0.0f, 0.0f, 1.0f // 左上&#125;; 新的顶点格式： 123// 解析纹理坐标并启用glVertexAttribPointer(2, 2, GL_FLOAT, GL_FALSE, 8 * sizeof(float), (void*)(6 * sizeof(float)));glEnableVertexAttribArray(2); 顶点着色器： 1234567891011121314#version 330 corelayout (location = 0) in vec3 aPos;layout (location = 1) in vec3 aColor;layout (location = 2) in vec2 aTexCoord;out vec3 ourColor;out vec2 TexCoord;void main()&#123; gl_Position = vec4(aPos, 1.0); ourColor = aColor; TexCoord = aTexCoord;&#125; 片段着色器： 1234567891011121314#version 330 coreout vec4 FragColor;in vec3 ourColor;in vec2 TexCoord;// 采样器uniform sampler2D ourTexture;void main()&#123; // 使用纹理坐标在采样器中采样纹理的颜色 FragColor = texture(ourTexture, TexCoord);&#125; 绘制： 123glBindTexture(GL_TEXTURE_2D, texture);glBindVertexArray(VAO);glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); 运行程序： 6. 纹理单元个纹理的位置值通常称为一个纹理单元，纹理的默认纹理单元是0，它也是默认的激活纹理单元。有了纹理单元就可以在着色器中可以使用多于一个的纹理。通过把纹理单元赋值给采样器可以一次绑定多个纹理，然后激活对应的纹理单元，如下： 123// 在绑定纹理之前先激活纹理单元，纹理单元0默认被激活glActiveTexture(GL_TEXTURE0);glBindTexture(GL_TEXTURE_2D, texture); 修改片段着色器： 123456789101112131415#version 330 core...uniform sampler2D texture1;// 新增uniform sampler2D texture2;void main()&#123; // 根据第三个参数进行线性插值 // 如果第三个值是0.0，它会返回第一个输入 // 如果是1.0，会返回第二个输入值 // 0.2会返回80%的第一个输入颜色和20%的第二个输入颜色，即返回两个纹理的混合色 FragColor = mix(texture(texture1, TexCoord), texture(texture2, TexCoord), 0.2);&#125; 使用第二张纹理： 12345678910111213141516171819202122232425262728// 修改顶点float vertices[] = &#123; // ---- 位置 ---- ---- 颜色 ---- - 纹理坐标 - 0.5f, 0.5f, 0.0f, 1.0f, 0.0f, 0.0f, 2.0f, 2.0f, // 右上 0.5f, -0.5f, 0.0f, 0.0f, 1.0f, 0.0f, 2.0f, 0.0f, // 右下 -0.5f, -0.5f, 0.0f, 0.0f, 0.0f, 1.0f, 0.0f, 0.0f, // 左下 -0.5f, 0.5f, 0.0f, 1.0f, 1.0f, 0.0f, 0.0f, 2.0f // 左上&#125;;// 翻转y轴stbi_set_flip_vertically_on_load(true);// 载入纹理图片...// 绑定和激活glActiveTexture(GL_TEXTURE0);glBindTexture(GL_TEXTURE_2D, texture1);glActiveTexture(GL_TEXTURE1);glBindTexture(GL_TEXTURE_2D, texture2);// 设置uniform变量之要先前激活着色器程序ourShader.use();// 设置采样器对应的纹理单元glUniform1i(glGetUniformLocation(ourShader.ID, &quot;texture1&quot;), 0);glUniform1i(glGetUniformLocation(ourShader.ID, &quot;texture2&quot;), 1); glBindVertexArray(VAO);glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); 运行程序：","categories":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://raoyuqi.github.io/tags/OpenGL/"}]},{"title":"着色器","slug":"graphic/opengl/着色器","date":"2023-07-18T13:20:44.000Z","updated":"2023-07-21T13:20:44.233Z","comments":false,"path":"2023/07/18/graphic/opengl/着色器/","link":"","permalink":"https://raoyuqi.github.io/2023/07/18/graphic/opengl/%E7%9D%80%E8%89%B2%E5%99%A8/","excerpt":"","text":"1. 程序结构123456789101112131415#version version_numberin type in_variable_name;in type in_variable_name;out type out_variable_name;uniform type uniform_name;int main()&#123; // 处理输入并进行一些图形操作 ... // 输出处理过的结果到输出变量 out_variable_name = weird_stuff_we_processed;&#125; 2. 输入与输出着色器虽然都是独立的小程序，但是最后经过编译链接后都是一个整体的一部分，所以每个着色器都通过输入和输出进行数据交互。GLSL定义了in和out关键字专门来实现这个目的，遵循原则：输出变量与下一个着色器阶段的输入匹配（类型与变量名完全一致），就会传递下去。 顶点着色器可以使用location指定输入变量，实现可以在CPU上配置顶点属性，从顶点数据中直接接收输入，如layout (location &#x3D; 0) in vec3 pos。 也可以忽略layout (location = 0)标识符，使用glGetAttribLocation查询属性位置值(Location)，在着色器中设置可以节省OpenGL的工作量。 顶点着色器 12345678910#version 330 corelayout (location = 0) in vec3 aPos; // 位置变量的属性位置值为0out vec4 vertexColor; // 为片段着色器指定一个颜色输出void main()&#123; gl_Position = vec4(aPos, 1.0); // 注意我们如何把一个vec3作为vec4的构造器的参数 vertexColor = vec4(0.5, 0.0, 0.0, 1.0); // 把输出变量设置为暗红色&#125; 片段着色器 123456789#version 330 coreout vec4 FragColor;in vec4 vertexColor; // 从顶点着色器传来的输入变量（名称相同、类型相同）void main()&#123; FragColor = vertexColor;&#125; 片段着色器需要输出最终像素颜色，如果没有定义输出颜色会显示黑或白，这里颜色通过顶点着色器发送。vertexColor在两个着色器中类型和变量名完全一致，因此在编译链接着色器程序的过程中，OpenGL会把两个变量链接在一起，使它们可以发送数据。 运行程序： 3. Uniform特点： 支持从CPU发送数据到GPU 变量是全局的，它可以被着色器程序的任意着色器在任意阶段访问 论你把uniform值设置成什么，uniform会一直保存它们的数据，直到被重置或更新 声明了一个uniform却在GLSL代码中没用过，编译器会静默移除这个变量，最后编译出的版本中并不会包含它 修改片段着色器代码： 123456789#version 330 coreout vec4 FragColor;uniform vec4 ourColor; // 在OpenGL程序代码中设定这个变量void main()&#123; FragColor = ourColor;&#125; 在CPU中传递颜色数据： 1234567891011121314151617181920212223242526272829303132while(!glfwWindowShouldClose(window))&#123; // 输入 processInput(window); // 渲染 // 清除颜色缓冲 glClearColor(0.2f, 0.3f, 0.3f, 1.0f); glClear(GL_COLOR_BUFFER_BIT); // 记得激活着色器 glUseProgram(shaderProgram); // 获取运行时间 float timeValue = glfwGetTime(); // 颜色分量 float greenValue = (sin(timeValue) / 2.0f) + 0.5f; // 查询uniform ourColor的位置值，返回-1代表没有找到这个位置值 int vertexColorLocation = glGetUniformLocation(shaderProgram, &quot;ourColor&quot;); // 激活着色器程序 glUseProgram(shaderProgram); // 设置颜色值，更新uniform值之前必须先激活着色器程序 glUniform4f(vertexColorLocation, 0.0f, greenValue, 0.0f, 1.0f); // 绘制三角形 glBindVertexArray(VAO); glDrawArrays(GL_TRIANGLES, 0, 3); // 交换缓冲并查询IO事件 glfwSwapBuffers(window); glfwPollEvents();&#125; 运行程序： 4. 链接更多属性把颜色添加到顶点数据中： 123456float vertices[] = &#123; // 位置 // 颜色 0.5f, -0.5f, 0.0f, 1.0f, 0.0f, 0.0f, // 右下 -0.5f, -0.5f, 0.0f, 0.0f, 1.0f, 0.0f, // 左下 0.0f, 0.5f, 0.0f, 0.0f, 0.0f, 1.0f // 顶部&#125;; 调整顶点着色器： 1234567891011#version 330 corelayout (location = 0) in vec3 aPos; // 位置变量的属性位置值为 0 layout (location = 1) in vec3 aColor; // 颜色变量的属性位置值为 1out vec3 ourColor; // 向片段着色器输出一个颜色void main()&#123; gl_Position = vec4(aPos, 1.0); ourColor = aColor; // 将ourColor设置为我们从顶点数据那里得到的输入颜色&#125; 删除片段着色器中的uniform变量： 12345678#version 330 coreout vec4 FragColor; in vec3 ourColor;void main()&#123; FragColor = vec4(ourColor, 1.0);&#125; 添加了另一个顶点属性，并且更新了VBO的内存后，VBO内存中的数据布局： 解析顶点数据： 123456// 位置属性，位置0glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)0);glEnableVertexAttribArray(0);// 颜色属性，位置1，起始偏移3 * sizeof(float)glVertexAttribPointer(1, 3, GL_FLOAT, GL_FALSE, 6 * sizeof(float), (void*)(3 * sizeof(float)));glEnableVertexAttribArray(1); 运行程序： 5. 着色器类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121#ifndef SHADER_H#define SHADER_H#include &lt;glad/glad.h&gt;#include &lt;string&gt;#include &lt;fstream&gt;#include &lt;sstream&gt;#include &lt;iostream&gt;class Shader&#123;public: unsigned int ID; // constructor generates the shader on the fly // ------------------------------------------------------------------------ Shader(const char* vertexPath, const char* fragmentPath) &#123; // 1. retrieve the vertex/fragment source code from filePath std::string vertexCode; std::string fragmentCode; std::ifstream vShaderFile; std::ifstream fShaderFile; // ensure ifstream objects can throw exceptions: vShaderFile.exceptions (std::ifstream::failbit | std::ifstream::badbit); fShaderFile.exceptions (std::ifstream::failbit | std::ifstream::badbit); try &#123; // open files vShaderFile.open(vertexPath); fShaderFile.open(fragmentPath); std::stringstream vShaderStream, fShaderStream; // read file&#x27;s buffer contents into streams vShaderStream &lt;&lt; vShaderFile.rdbuf(); fShaderStream &lt;&lt; fShaderFile.rdbuf(); // close file handlers vShaderFile.close(); fShaderFile.close(); // convert stream into string vertexCode = vShaderStream.str(); fragmentCode = fShaderStream.str(); &#125; catch (std::ifstream::failure&amp; e) &#123; std::cout &lt;&lt; &quot;ERROR::SHADER::FILE_NOT_SUCCESSFULLY_READ: &quot; &lt;&lt; e.what() &lt;&lt; std::endl; &#125; const char* vShaderCode = vertexCode.c_str(); const char * fShaderCode = fragmentCode.c_str(); // 2. compile shaders unsigned int vertex, fragment; // vertex shader vertex = glCreateShader(GL_VERTEX_SHADER); glShaderSource(vertex, 1, &amp;vShaderCode, NULL); glCompileShader(vertex); checkCompileErrors(vertex, &quot;VERTEX&quot;); // fragment Shader fragment = glCreateShader(GL_FRAGMENT_SHADER); glShaderSource(fragment, 1, &amp;fShaderCode, NULL); glCompileShader(fragment); checkCompileErrors(fragment, &quot;FRAGMENT&quot;); // shader Program ID = glCreateProgram(); glAttachShader(ID, vertex); glAttachShader(ID, fragment); glLinkProgram(ID); checkCompileErrors(ID, &quot;PROGRAM&quot;); // delete the shaders as they&#x27;re linked into our program now and no longer necessary glDeleteShader(vertex); glDeleteShader(fragment); &#125; // activate the shader // ------------------------------------------------------------------------ void use() &#123; glUseProgram(ID); &#125; // utility uniform functions // ------------------------------------------------------------------------ void setBool(const std::string &amp;name, bool value) const &#123; glUniform1i(glGetUniformLocation(ID, name.c_str()), (int)value); &#125; // ------------------------------------------------------------------------ void setInt(const std::string &amp;name, int value) const &#123; glUniform1i(glGetUniformLocation(ID, name.c_str()), value); &#125; // ------------------------------------------------------------------------ void setFloat(const std::string &amp;name, float value) const &#123; glUniform1f(glGetUniformLocation(ID, name.c_str()), value); &#125;private: // utility function for checking shader compilation/linking errors. // ------------------------------------------------------------------------ void checkCompileErrors(unsigned int shader, std::string type) &#123; int success; char infoLog[1024]; if (type != &quot;PROGRAM&quot;) &#123; glGetShaderiv(shader, GL_COMPILE_STATUS, &amp;success); if (!success) &#123; glGetShaderInfoLog(shader, 1024, NULL, infoLog); std::cout &lt;&lt; &quot;ERROR::SHADER_COMPILATION_ERROR of type: &quot; &lt;&lt; type &lt;&lt; &quot;\\n&quot; &lt;&lt; infoLog &lt;&lt; &quot;\\n -- --------------------------------------------------- -- &quot; &lt;&lt; std::endl; &#125; &#125; else &#123; glGetProgramiv(shader, GL_LINK_STATUS, &amp;success); if (!success) &#123; glGetProgramInfoLog(shader, 1024, NULL, infoLog); std::cout &lt;&lt; &quot;ERROR::PROGRAM_LINKING_ERROR of type: &quot; &lt;&lt; type &lt;&lt; &quot;\\n&quot; &lt;&lt; infoLog &lt;&lt; &quot;\\n -- --------------------------------------------------- -- &quot; &lt;&lt; std::endl; &#125; &#125; &#125;&#125;;#endif 使用： 12345678Shader ourShader(&quot;path/to/shaders/shader.vs&quot;, &quot;path/to/shaders/shader.fs&quot;);...while(...)&#123; ourShader.use(); ourShader.setFloat(&quot;someUniform&quot;, 1.0f); ...&#125;","categories":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://raoyuqi.github.io/tags/OpenGL/"}]},{"title":"画三角形","slug":"graphic/opengl/画三角形","date":"2023-07-17T12:46:20.000Z","updated":"2023-07-21T13:20:50.162Z","comments":false,"path":"2023/07/17/graphic/opengl/画三角形/","link":"","permalink":"https://raoyuqi.github.io/2023/07/17/graphic/opengl/%E7%94%BB%E4%B8%89%E8%A7%92%E5%BD%A2/","excerpt":"","text":"1. 图形渲染管线1.1 概念图形渲染管线是个流水线，分为好几个阶段，主要的工作为：将3D空间中的坐标转换为屏幕空间的2D坐标，并最终把2D坐标转换为有颜色的像素，形成画面。 1.2 着色器图形渲染管线分为多个阶段，每个阶段会把前一个阶段的输出作为输入。每个阶段高度专门化，非常容易并行执行，因此大多数显卡都有成千上万个小处理核心，处理核心负责在GPU上为每个流水线阶段处运行各自的程序，达到在渲染管线中快速并行地处理数据，这些小程序就是着色器。OpenGL着色器是用OpenGL着色器语言(OpenGL Shading Language, GLSL)写的。 1.3 阶段如图，蓝色部分是可以自定义的部分： 顶点着色器 以顶点坐标作为输入，将其处理成齐次坐标。 图元装配 将顶点着色器输出的所有顶点作为输入，并将所有的点装配成指定的图元形状（点、三角形等）。 几何着色器 把图元装配形成的顶点集合作为输入，这个阶段可以产生新顶点，构造出新的图元来生成其它形状。 光栅化阶段 几何着色器的输出作为输入，这个阶段会把图元映射为最终屏幕上对应的像素，生成给片段着色器使用的片段。生成片段过程中会执行裁剪，丢弃超出视图以外的所有像素，提升下个阶段的效率。 片段着色器 这里会计算出像素最后显示的颜色，是所有OpenGL高级效果产生的地方。通常，片段着色器包含3D场景的数据（比如光照、阴影、光的颜色等等），这些数据可以被用来计算最终像素的颜色 Alpha测试和混合 这是最后一个阶段，会对片段进行一系列检测，如深度和模板测试，透明度测试及混合等。 现代OpenGL中，至少定义一个顶点着色器和片段着色器。 2. 绘制三角形 准备顶点数据 tip: OpenGL是3D图形库，因此指定的坐标需要是3D坐标；OpenGL只处理标准化设备坐标，即-1.0到1.0范围内的坐标，并不是简单地把3D坐标转换为屏幕上的2D像素。 给定如下输入坐标： 123456// 将每个z坐标设为0，让它看上去是2D的float vertices[] = &#123; -0.5f, -0.5f, 0.0f, 0.5f, -0.5f, 0.0f, 0.0f, 0.5f, 0.0f&#125;; 深度可以理解为z坐标，它代表一个像素在空间中和你的距离，如果被别的像素遮挡， 就看不到它了，将会被丢弃，以节省资源。 该组坐标在标准化设备中对应如下三角形： 接下来把顶点坐标传给渲染管线的第一个阶段（顶点着色器），顶点着色器会在GPU上创建内存，用来存储顶点数据，还要配置OpenGL如何解释这些内存，并且指定其如何发送给显卡。 创建VBO 通过顶点缓冲对象(Vertex Buffer Objects, VBO)管理这个内存，它会在GPU内存（通常被成为显存）中存储大量顶点。使用缓冲对象的好处是可以批量发送数据到显卡上，而不是每次发送一个顶点。从CPU把数据发送到显卡相对较慢，但是当数据发送至显卡的内存中后，顶点着色器几乎能立即访问顶点。 123456789// 创建VBO对象unsigned int VBO;glGenBuffers(1, &amp;VBO);// 绑定到GL_ARRAY_BUFFER，绑定后使用的任何（在GL_ARRAY_BUFFER目标上的）缓冲调用都会用来配置当前绑定的缓冲(VBO)glBindBuffer(GL_ARRAY_BUFFER, VBO);// 把顶点数据复制到缓冲的内存中glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); 希望显卡如何管理给定的数据的三种形式： - GL_STATIC_DRAW ：数据不会或几乎不会改变 - GL_DYNAMIC_DRAW：数据会被改变很多 - GL_STREAM_DRAW ：数据每次绘制时都会改变 这样顶点数据就被存储到显存中了，被VBO这个顶点缓冲对象所管理着。 着色器 用GLSL编写顶点着色器： 1234567891011// 版本号和核心模式#version 330 core// 设定了输入变量的位置值layout (location = 0)// 接收顶点数据in vec3 aPos;void main()&#123; gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0);&#125; 编译着色器 将第3步的着色器代码赋值给字符串： 1234567891011121314151617181920212223242526272829// 顶点着色器代码const char *vertexShaderSource = &quot;#version 330 core\\n&quot; &quot;layout (location = 0) in vec3 aPos;\\n&quot; &quot;void main()\\n&quot; &quot;&#123;\\n&quot; &quot; gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0);\\n&quot; &quot;&#125;\\0&quot;;// 创建一个顶点着色器对象unsigned int vertexShader;vertexShader = glCreateShader(GL_VERTEX_SHADER);// 着色器源码附加到着色器对象上glShaderSource(vertexShader, 1, &amp;vertexShaderSource, NULL);// 编译glCompileShader(vertexShader);// 片段着色器代码const char *fragmentShaderSource = &quot;#version 330 core\\n&quot; &quot;layout (location = 0) out vec4 FragColor;\\n&quot; &quot;void main()\\n&quot; &quot;&#123;\\n&quot; &quot; FragColor = vec4(1.0f, 0.5f, 0.2f, 1.0f);\\n&quot; &quot;&#125;\\0&quot;;unsigned int fragmentShader;fragmentShader = glCreateShader(GL_FRAGMENT_SHADER);glShaderSource(fragmentShader, 1, &amp;fragmentShaderSource, NULL);glCompileShader(fragmentShader); 着色器程序 着色器程序对象是多个着色器最终链接完成的版本。如果要使用刚才编译的着色器必须把它们链接(Link)为一个着色器程序对象，然后在渲染对象的时候激活这个着色器程序。已激活着色器程序的着色器将在发送渲染调用的时候被使用。 1234567891011121314// 创建着色器程序对象unsigned int shaderProgram;shaderProgram = glCreateProgram();// 附加着色器对象到程序glAttachShader(shaderProgram, vertexShader);glAttachShader(shaderProgram, fragmentShader);// 链接glLinkProgram(shaderProgram);// 激活着色器程序glUseProgram(shaderProgram);// 释放不再需要的资源glDeleteShader(vertexShader);glDeleteShader(fragmentShader); 到这一步已经把输入顶点数据发送给了GPU，并指示了GPU如何在顶点和片段着色器中处理这些数据。接下来需要告诉OpenGL如何解释内存中的顶点数据，以及它该如何将顶点数据链接到顶点着色器的属性上。 链接顶点属性 必须手动指定输入数据的哪一个部分对应顶点着色器的哪一个顶点属性。所以必须在渲染前指定OpenGL该如何解释顶点数据，顶点缓冲数据会被解析为下面这样子： 1234// 解析顶点数据glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);// 以顶点属性位置值作为参数，启用顶点属性，默认是禁用的glEnableVertexAttribArray(0); 顶点数组对象VAO 顶点数组对象(Vertex Array Object, VAO)可以像顶点缓冲对象那样被绑定，任何随后的顶点属性调用都会储存在这个VAO中。好处是，当配置顶点属性指针时，只需要将那些调用执行一次，之后再绘制物体的时候只需要绑定相应的VAO就行了，因为设置的所有状态都将存储在VAO中。 123// 创建一个VAO对象unsigned int VAO;glGenVertexArrays(1, &amp;VAO); 当打算绘制多个物体时，首先要生成&#x2F;配置所有的VAO（和必须的VBO及属性指针)，然后储存它们供后面使用。当打算绘制物体的时候就拿出相应的VAO，绑定它，绘制完物体后，再解绑VAO。这段代码应该看起来像这样： 123456789101112131415161718// ..:: 初始化代码（只运行一次 (除非你的物体频繁改变)） :: ..// 1. 绑定VAOglBindVertexArray(VAO);// 2. 把顶点数组复制到缓冲中供OpenGL使用glBindBuffer(GL_ARRAY_BUFFER, VBO);glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);// 3. 设置顶点属性指针glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);glEnableVertexAttribArray(0);// [...]// ..:: 绘制代码（渲染循环中） :: ..// 绘制物体glUseProgram(shaderProgram);glBindVertexArray(VAO);someOpenGLFunctionThatDrawsOurTriangle();// 解绑VAO 绘制三角形 123456// 激活着色器程序glUseProgram(shaderProgram);// 绑定VAOglBindVertexArray(VAO);// 画三角形，顶点数组的起始索引为0，绘制3个顶点glDrawArrays(GL_TRIANGLES, 0, 3); 结果： 3. 元素缓冲对象元素缓冲对象(Element Buffer Object，EBO)，也叫索引缓冲对象(Index Buffer Object，IBO)。假设不绘制一个三角形而是绘制一个矩形。可以绘制两个三角形来组成一个矩形： 12345678910float vertices[] = &#123; // 第一个三角形 0.5f, 0.5f, 0.0f, // 右上角 0.5f, -0.5f, 0.0f, // 右下角 -0.5f, 0.5f, 0.0f, // 左上角 // 第二个三角形 0.5f, -0.5f, 0.0f, // 右下角 -0.5f, -0.5f, 0.0f, // 左下角 -0.5f, 0.5f, 0.0f // 左上角&#125;; 一个矩形只有4个而不是6个顶点，这样会产生50%的额外开销，如果有包括上千个三角形的模型，这会产生一大堆浪费。可以通过只储存不同的顶点，并设定绘制这些顶点的顺序。这样子只要储存4个顶点就能绘制矩形了，之后只要指定绘制的顺序就行。元素缓冲区对象就是用来做这个的。 EBO是一个缓冲区，就像一个顶点缓冲区对象一样，它存储OpenGL用来决定要绘制哪些顶点的顺序。定义不重复的顶点和绘制出矩形所需的索引顺序： 123456789101112131415161718192021222324float vertices[] = &#123; 0.5f, 0.5f, 0.0f, // 右上角 0.5f, -0.5f, 0.0f, // 右下角 -0.5f, -0.5f, 0.0f, // 左下角 -0.5f, 0.5f, 0.0f // 左上角&#125;;// 注意索引从0开始! // 此例的索引(0,1,2,3)就是顶点数组vertices的下标，// 这样可以由下标代表顶点组合成矩形unsigned int indices[] = &#123; 0, 1, 3, // 第一个三角形 1, 2, 3 // 第二个三角形&#125;;// 创建EBO对象unsigned int EBO;glGenBuffers(1, &amp;EBO);// 把索引复制到缓冲里glBufferData(GL_ELEMENT_ARRAY_BUFFER, sizeof(indices), indices, GL_STATIC_DRAW);// 从索引缓冲区渲染三角形glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, EBO);glDrawElements(GL_TRIANGLES, 6, GL_UNSIGNED_INT, 0); 结果： 线框模式 glPolygonMode(GL_FRONT_AND_BACK, GL_LINE)函数配置OpenGL如何绘制图元。 第一个参数表示打算将其应用到所有的三角形的正面和背面，第二个参数表示用线来绘制。 之后的绘制调用会一直以线框模式绘制三角形，直到调用glPolygonMode(GL_FRONT_AND_BACK, GL_FILL)将其设置回默认模式。","categories":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://raoyuqi.github.io/tags/OpenGL/"}]},{"title":"创建窗口","slug":"graphic/opengl/创建窗口","date":"2023-07-15T01:01:48.000Z","updated":"2023-07-21T13:20:55.630Z","comments":false,"path":"2023/07/15/graphic/opengl/创建窗口/","link":"","permalink":"https://raoyuqi.github.io/2023/07/15/graphic/opengl/%E5%88%9B%E5%BB%BA%E7%AA%97%E5%8F%A3/","excerpt":"","text":"1. 实例化GLFW窗口12345678910111213int main()&#123; glfwInit(); //设置OpenGL主版本号(Major)和次版本号(Minor) glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); //告诉GLFW使用的是核心模式(Core-profile) glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); //Mac OS X系统的额外设置 //glfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE); return 0;&#125; 2. 创建窗口1234567891011121314int main()&#123; //创建窗口 GLFWwindow* window = glfwCreateWindow(800, 600, &quot;Hello Word&quot;, NULL, NULL); if (window == NULL) &#123; std::cout &lt;&lt; &quot;Failed to create GLFW window&quot; &lt;&lt; std::endl; glfwTerminate(); return -1; &#125; //通知GLFW将窗口的上下文设置为当前线程的主上下文了 glfwMakeContextCurrent(window);&#125; 3. 初始化GLADGLAD是用来管理OpenGL的函数指针的，所以在调用任何OpenGL的函数之前我们需要初始化GLAD。 12345678910int main()&#123; //GLAD是用来管理OpenGL的函数指针的 //调用任何OpenGL的函数之前先需要初始化GLAD if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress)) &#123; std::cout &lt;&lt; &quot;Failed to initialize GLAD&quot; &lt;&lt; std::endl; return -1; &#125;&#125; 给GLAD传入了用来加载系统相关的OpenGL函数指针地址的函数。GLFW的glfwGetProcAddress根据编译的系统定义了正确的函数。 4. 设置视口必须告诉OpenGL渲染窗口的尺寸大小，即视口(Viewport)，这样OpenGL才只能知道怎样根据窗口大小显示数据和坐标。并且注册窗口大小改变的回调监听。 12345678910111213void framebuffer_size_callback(GLFWwindow* window, int width, int height);int main()&#123; glViewport(0, 0, 800, 600); //告诉GLFW每当窗口调整大小的时候调用framebuffer_size_callback函数更新视口 glfwSetFramebufferSizeCallback(window, framebuffer_size_callback);&#125;void framebuffer_size_callback(GLFWwindow* window, int width, int height)&#123; glViewport(0, 0, width, height);&#125; 5. 渲染循环添加渲染循环，在GLFW退出前一直保持运行。 1234567int main()&#123; //交换缓冲 glfwSwapBuffers(window); //函数检查有没有触发什么事件（比如键盘输入、鼠标移动等）、更新窗口状态，并调用对应的回调函数 glfwPollEvents();&#125; 双缓冲(Double Buffer) 应用程序使用单缓冲绘图时可能会存在图像闪烁的问题。 这是因为生成的图像不是一下子被绘制出来的，而是按照从左到右，由上而下逐像素地绘制而成的。 最终图像不是在瞬间显示给用户，而是通过一步一步生成的，这会导致渲染的结果很不真实。 为了规避这些问题，我们应用双缓冲渲染窗口应用程序。前缓冲保存着最终输出的图像，它会在屏幕上显示；而所有的的渲染指令都会在后缓冲上绘制。当所有的渲染指令执行完毕后，我们交换(Swap)前缓冲和后缓冲，这样图像就立即呈显出来，之前提到的不真实感就消除了。 6. 输入12345678910111213141516171819//监听输入void processInput(GLFWwindow* window);void processInput(GLFWwindow* window)&#123; if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) glfwSetWindowShouldClose(window, true);&#125;int main()&#123; //输入 processInput(window); //交换缓冲 glfwSwapBuffers(window); //函数检查有没有触发什么事件（比如键盘输入、鼠标移动等）、更新窗口状态，并调用对应的回调函数 glfwPollEvents();&#125; 7. 资源释放123456789int main()&#123; //... //渲染循环结束后需要正确释放/删除之前的分配的所有资源 glfwTerminate(); return 0;&#125;","categories":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://raoyuqi.github.io/tags/OpenGL/"}]},{"title":"OpenGL环境部署","slug":"graphic/opengl/OpenGL环境部署","date":"2023-07-13T13:35:40.000Z","updated":"2023-07-21T13:21:00.893Z","comments":false,"path":"2023/07/13/graphic/opengl/OpenGL环境部署/","link":"","permalink":"https://raoyuqi.github.io/2023/07/13/graphic/opengl/OpenGL%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/","excerpt":"","text":"1. 概述OpenGL本身并不是一个API，它仅仅是一个由Khronos组织制定并维护的规范。基于该规范编程在不同操作系统会有差异，借助库可以节省编写操作系统相关的代码，流行的库有：GLUT，SDL，SFML和GLFW。 2. 部署环境2.1 GLFW一个专门针对OpenGL的C语言库，提供了一些渲染物体所需的最低限度的接口。允许用户创建OpenGL上下文、定义窗口参数以及处理用户输入等。 从官网下载并将其解压，接着创建一个build目录作为最终导出目录，然后使用CMake工具生成工程文件。 下载CMake并安装，执行cmake-gui，如下设置： 点击Generate按钮，生成的工程文件会在build文件夹中。 在build文件夹里可以找到GLFW.sln文件，用Visual Studio 2019打开。因为CMake已经配置好了项目，并按照默认配置将其编译为64位的库，所以直接点击Build Solution(生成解决方案)，然后在build&#x2F;src&#x2F;Debug文件夹内就会出现我们编译出的库文件glfw3.lib。 2.2 GLFW链接建立一个新的目录用来存放所有的第三方库文件和头文件，建议包含Libs和Include文件夹，在这里存放OpenGL工程用到的所有第三方库和头文件。 打开Visual Studio，创建一个新的项目。选择Visual C++，然后选择空项目，接着将项目从x86更改为x64。为了使程序能够使用GLFW，需要把GLFW库链接进工程： 在Windows平台，opengl32.lib已经包含在Microsoft SDK里了，它在Visual Studio安装的时候就默认安装了。只需将opengl32.lib添加进连接器设置里就行了。OpenGL库64位版本的文件名仍然是opengl32.lib（和32位版本一样）。 2.3 GLAD由于OpenGL只是一个标准&#x2F;规范，具体的实现是由驱动开发商针对特定显卡实现的。OpenGL驱动版本众多，它大多数函数的位置都无法在编译时确定下来，需要在运行时查询。开发者需要在运行时获取函数地址并将其保存在一个函数指针中供以后使用。取得地址的方法因平台而异，在Windows上类似这样： 1234567// 定义函数原型typedef void (*GL_GENBUFFERS) (GLsizei, GLuint*);// 找到正确的函数并赋值给函数指针GL_GENBUFFERS glGenBuffers = (GL_GENBUFFERS)wglGetProcAddress(&quot;glGenBuffers&quot;);// 现在函数可以被正常调用了GLuint buffer;glGenBuffers(1, &amp;buffer); 使用GLAD库可以简化这个过程。 打开GLAD的在线服务，如下设置： 点击Generate按钮来生成库文件，下载GLAD生成的压缩包并解压，将两个头文件目录（glad和KHR）复制到Include文件夹中，并添加glad.c文件到工程中，到此环境配置就完成了。","categories":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://raoyuqi.github.io/tags/OpenGL/"}]},{"title":"Hello World","slug":"hello-world","date":"2023-07-11T13:30:41.175Z","updated":"2023-07-11T13:30:41.175Z","comments":true,"path":"2023/07/11/hello-world/","link":"","permalink":"https://raoyuqi.github.io/2023/07/11/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"Uniy","slug":"Uniy","permalink":"https://raoyuqi.github.io/categories/Uniy/"},{"name":"性能优化","slug":"Uniy/性能优化","permalink":"https://raoyuqi.github.io/categories/Uniy/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"}],"tags":[{"name":"Uniy","slug":"Uniy","permalink":"https://raoyuqi.github.io/tags/Uniy/"},{"name":"性能优化","slug":"性能优化","permalink":"https://raoyuqi.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"name":"合并Mesh","slug":"合并Mesh","permalink":"https://raoyuqi.github.io/tags/%E5%90%88%E5%B9%B6Mesh/"},{"name":"Dots","slug":"Dots","permalink":"https://raoyuqi.github.io/tags/Dots/"},{"name":"图形学","slug":"图形学","permalink":"https://raoyuqi.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://raoyuqi.github.io/tags/OpenGL/"}]}